<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CurrentHashMap源码解析]]></title>
    <url>%2FJava%E9%9B%86%E5%90%88%2FCurrentHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[Lorem ipsumLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eu tempor dolor. Nulla hendrerit convallis purus et elementum. Suspendisse non magna vel justo tincidunt finibus. Nullam dui erat, malesuada eget viverra non, finibus a nisl.]]></content>
      <categories>
        <category>Java集合</category>
      </categories>
      <tags>
        <tag>semper</tag>
        <tag>fermentum</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Funcategorized%2FJava%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E6%95%B0%E7%BB%84%2Findex.html</url>
    <content type="text"><![CDATA[Java数据结构：数组数组是什么在计算机科学中，数组数据结构（英语：array data structure），简称数组（英语：Array），是由相同类型的元素（element）的集合所组成的数据结构，分配一块连续的内存来存储。利用元素的索引（index）可以计算出该元素对应的存储地址。 Java中的数组在Java中，数组是一种效率最高的存储和随机访问对象引用序列的方式。数组就是一个简单的线性序列，这使得元素访问非常快速。但是为这种速度所付出代价是数组对象大小被固定，并且在其声明周期中不可改变。 数组内的元素既可以是基本数据类型，也可以是引用数据类型。区别在于对象数据保存的是引用，基本类型数组直接保存基本类型的值。 数组的创建12345678910111213141516//声明一个长度为2的int数组int[] ints = new int[2];//初始化一个保存1,2元素的数组int[] intArr = new int[] &#123;1, 2&#125;;//初始化一个保存1,2,3,4的数组int[] arr = &#123;1, 2, 3, 4&#125;;//声明一个为初始化的数组，我们没办法做任何事情User[] userArr;//声明一个长度为2的User类数组User[] user = new User[2];//初始化一个User数组，里面有两个User对象的引用userArr = new User[] &#123;new User(), new User()&#125;;//初始化一个User数组，里面有两个User对象的引用User[] userArr2 = &#123;new User(), new User()&#125;; 数组是对象吗？Java里面的数组到底是什么？ 答案是对象。 证据：123int[] arr = &#123;1, 2, 3, 4&#125;;String name = arr.getClass().getSuperclass().getName();System.out.println(name); 输出:java.lang.Object 数组的父类是Object。 Java数组这个对象太特俗了，以至于我们没办法把它当做对象处理，甚至我们都找不到类文件与之对应，但是找不到不代表没有。数组对象并不是从某个类实例化来的，而是由JVM直接创建的，因此查看类名的时候会发现是很奇怪的类似于”[I”这样的样子： 123456789int[] arr = &#123;1, 2, 3, 4&#125;;String name = arr.getClass().getName();System.out.println(name);//输出：[IUser[] userArr2 = &#123;new User(), new User()&#125;;String userArrClassName = userArr2.getClass().getName();System.out.println(userArrClassName);输出:[Lcom.weimai.medical.admin.controller.User; length返回的是什么？length只表示数组能够容纳多少元素，也就是说，length是数组的大小，而不是实际存放的元素个数。 Array类是做什么的？我们点开Array类看一下。 12345678910/** * The &#123;@code Array&#125; class provides static methods to dynamically create and * access Java arrays. * * &lt;p&gt;&#123;@code Array&#125; permits widening conversions to occur during a get or set * operation, but throws an &#123;@code IllegalArgumentException&#125; if a narrowing * conversion would occur. * * @author Nakul Saraiya */ 首先看到这样一段注释，它的第一句就说明了Array类的作用：Array类提供静态方法来创建和访问Java数组。 再看下它的类声明：12public finalclass Array &#123;&#125; final类，不可修改。看到这里基本可以断定Array类和我们创建数组这个动作毫无关系，并且也不是真正的数组类。 正如类注释说明的那样，Array类可以帮助我们快速操作数组，它更像一个工具类，底层基本都是native方法。 比如： 12345int[] arr = &#123;1, 2, 3, 4&#125;;//取数组索引为1的元素System.out.println(Array.get(arr, 1)); //2//取数组索引为3的元素System.out.println(Array.get(arr, 3)); //4 下面正式回答你的问题:问题一： 答案是没有关系，因为Array类是final的，Array类提供了一些静态方法帮助我们创建和访问数组。 问题二： 在Java中，没有类文件与数组对应，数组是在JVM中动态生成的。 问题三： 数组的长度，在动态生成的数组对象的对象头里有一个 _length 字段，记录数组长度。获取数组长度是由一条特定的指令arraylength实现。 Array.getLength()和arr.length是一样的效果，代码验证如下:123456//声明一个容量为2的数组int[] ints = new int[2];//指定索引0的值为1ints[0] = 1;System.out.println(ints.length); //2System.out.println(Array.getLength(ints); //2 问题四： 不知道你是指底层JVM的判断还是我们程序员自己判断。感觉应该是指底层JVM，很抱歉，水平有限，我也不清楚，但是感觉和底层的压栈出栈什么的有关系，不知道有没有使用length判断。 希望以上回答能帮到你，关注我的专栏Java技术栈，让我们一起成长]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Funcategorized%2FJava%E9%9B%86%E5%90%88%E4%B9%8BJDK1.8CopyOnWriteArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[java集合系列之JDK8CopyOnWriteArrayList源码解析 概述CopyOnWriteArrayList是java.util.concurrent包中的一员，是ArrayList的线程安全版本。其实现原理正如它的类名描述的一样，在进行修改的时候，复制一份数据为新数组，并在新数组上面修改，最后将原来的数组引用指向新数组。 构造方法CopyOnWriteArrayList拥有三个构造函数，分别是空参构造、传递一个集合的构造、传递一个数组的构造,下面对这三个构造函数一一讲解 public CopyOnWriteArrayList()12345678910111213/** * 构造一个空的list */public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125;/** * Sets the array. */final void setArray(Object[] a) &#123; array = a;&#125; 空参构造就是创建了一个新的长度为0的Object数组，并且将该数组赋值给使用volatile修饰的成员变量array 1private transient volatile Object[] array; public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c)123456789101112131415161718192021/** * 使用特定的集合元素创建 * * @param c 集合元素 * @throws NullPointerException 如果元素为空，抛出NPE */public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) //如果传递的集合是CopyOnWriteArrayList类，直接调用getArray()返回成员变量array的值 elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; //如果不是，调用toArray()方法转换为数组 elements = c.toArray(); if (elements.getClass() != Object[].class) // c.toArray 返回的可能不是Object[]数组,如果不是，将数组拷贝到Object数组 elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; //设置成员变量的值 setArray(elements);&#125; 该构造方法首先将集合转换为数组，然后赋值给成员变量array。 public CopyOnWriteArrayList(E[] toCopyIn)12345678910/** * 使用指定数组构造 * * @param toCopyIn the array (a copy of this array is used as the * internal array) * @throws NullPointerException if the specified array is null */public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 给构造方法是将传递进来的数组通过拷贝的方式复制到Object数组，然后赋值给成员变量array。 方法解析add()123456789101112131415161718192021222324252627/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; //获取可重入锁锁 final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; //获取旧数组的元素以及长度 Object[] elements = getArray(); int len = elements.length; //创建一个新的数组,长度为原来的长度+1，将旧数组的元素拷贝到新的数组 Object[] newElements = Arrays.copyOf(elements, len + 1); //将要添加的元素放在新数组最后 newElements[len] = e; //将引用指向新的数组，旧数组被GC回收 setArray(newElements); return true; &#125; finally &#123; //释放锁 lock.unlock(); &#125;&#125; remove()12345678910111213141516171819202122232425262728293031323334353637/** * 删除指定数组指定位置上的元素，并且返回被删除的元素 * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; //获取锁 final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; //获取旧数组的元素和长度 Object[] elements = getArray(); int len = elements.length; //调用get()方法获取指定索引的元素 E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) //如果删除的是最后一个元素，直接copy第一个元素到倒数第一个元素为一个新的数组 setArray(Arrays.copyOf(elements, len - 1)); else &#123; //如果不是最后一个元素，分为两步拷贝 Object[] newElements = new Object[len - 1]; //拷贝被删除元素所在位置的前半段元素 System.arraycopy(elements, 0, newElements, 0, index); //拷贝被删除元素所在位置的后半段元素 System.arraycopy(elements, index + 1, newElements, index, numMoved); //设置值 setArray(newElements); &#125; return oldValue; &#125; finally &#123; //释放锁 lock.unlock(); &#125;&#125; get()1234567891011public E get(int index) &#123; return get(getArray(), index);&#125;final Object[] getArray() &#123; return array;&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125; get()的实现很简单，就是返回”volatile数组“中的第index个元素。 iterator()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125;static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** 数组快照 */ private final Object[] snapshot; /** 游标 */ private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; //保存数组的快照 snapshot = elements; &#125; public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; //获取下一个元素 @SuppressWarnings("unchecked") public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; //获取上一个元素 @SuppressWarnings("unchecked") public E previous() &#123; if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor-1; &#125; /** * 不支持remove */ public void remove() &#123; throw new UnsupportedOperationException(); &#125; /** * 不支持set */ public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; /** * 不支持add */ public void add(E e) &#123; throw new UnsupportedOperationException(); &#125; @Override public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); Object[] elements = snapshot; final int size = elements.length; for (int i = cursor; i &lt; size; i++) &#123; @SuppressWarnings("unchecked") E e = (E) elements[i]; action.accept(e); &#125; cursor = size; &#125; &#125; 创建迭代器的时候, 会保存数组元素的快照（有一个引用指向原数组）。 COWIterator不支持修改元素的操作。例如，对于remove(), set(), add()操作都会抛出UnsupportedOperationException！ 总结1.CopyOnWriteArrayList是线程安全的，通过volatile和互斥锁以及写时复制保存线程安全。2.修改操作(add、remove、set等)由于需要拷贝数组，性能损耗相对比较大。3.使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。迭代过程如果有修改操作会抛出UnsupportedOperationException，而不是ConcurrentModificationException，所以CopyOnWriteArrayList没有fail-fast机制。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Funcategorized%2FJava%E9%9B%86%E5%90%88%E4%B9%8BJDK1.8HashSet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[前面分析了ArrayList和HashMap的源码，今天分析下HashSet的源码。HashSet作为Java集合框架的一员，也是非常重要的，虽然平时用的没有前面两个多，但是在一些特定的场景可以帮助我们快速解决问题，所以掌握其特性也是非常重要的。 类注释首先还是先看下官方的类注释，快速了解HashSet的特性。 此类实现Set接口，由哈希表（实际上是HashMap实例）支持。它不能保证集合的迭代顺序;特别是，它不保证顺序一直保持不变。该类允许null元素。如果Hash函数能够很完美的分散各个元素到桶上，该类的基本操作（add, remove, contains and size）提供恒定的时间性能。 迭代此集合需要的时间与HashSet实例的大小（元素数量）以及HashMap实例的“容量”（桶数）之和成比例。因此，如果迭代性能很重要，则不要将初始容量设置得太高（或负载因子太低）。请注意，此实现不同步。如果多个线程同时访问哈希集合，并且至少有一个线程修改了该即可，则必须在外部进行同步。这通常通过在自然封装集合的某个对象上进行同步来实现。如果不存在此类对象，则应使用Collections.synchronizedSet方法“包装”该集合。这最好在创建时完成，以防止对集合的意外不同步访问：Set s = Collections.synchronizedSet（new HashSet（…））; 这个类的迭代器方法返回的迭代器是快速失败的：如果在创建迭代器之后的任何时候修改了set，​​除了通过迭代器自己的remove方法之外，Iterator都将抛出ConcurrentModificationException。因此，在并发修改的情况下，迭代器快速而干净地失败，而不是在未来的未确定时间冒着任意的，非确定性行为的风险。 请注意，迭代器的快速失败行为无法阿紫存在不同步的并发修改时做出任何硬性保证。快速失败迭代器会尽最大努力抛出ConcurrentModificationException。因此，不要编写这个异常的程序：迭代器的快速失败行为应仅用于检测错误。 由于HashSet的底层是HashMap,它的类注释和HashMap差不多，其特性也和HashMap差不多。 构造方法同HashMap一样，HashSet也有4个构造方法 HashSet()构建一个空的set集合，其底层的HashMap实例使用默认的初始容量(16)和加载因子(0.75)。 HashSet(Collection&lt;? extends E&gt; c)使用其他集合创建一个新得HashSet HashSet(int initialCapacity)构建一个空的set集合，其底层的HashMap实例使用传入的初始容量和默认加载因子(0.75)。 HashSet(int initialCapacity, float loadFactor)构建一个空的set集合，其底层的HashMap实例使用传入的初始容量和加载因子。 我们看一下第一个和第四个构造方法 123456/** * 构建一个空的set集合，其底层的HashMap实例使用默认的初始容量(16)和加载因子(0.75)。 */public HashSet() &#123; map = new HashMap&lt;&gt;();&#125; 1234567891011/** * 构建一个空的set集合，其底层的HashMap实例使用传入的初始容量和加载因子。 * * @param initialCapacity 初始容量 * @param loadFactor 加载因子 * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 成员变量123456789/** * 存放元素的map */private transient HashMap&lt;E,Object&gt; map;/** * HashMap的value值 */private static final Object PRESENT = new Object(); 成员方法add123456/** * 将元素放到map中，key是要添加的元素e，value是final修饰的object对象。 */public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; remove123456/** * 从HashMap中移除元素o，如果元素存在返回true，否则返回false */public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; size12345678/** * 返回HashMap中元素的个数 * * @return the number of elements in this set (its cardinality) */public int size() &#123; return map.size();&#125; contains123456789/** * 判断HashMap中是否包含某个元素 * * @param o element whose presence in this set is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this set contains the specified element */public boolean contains(Object o) &#123; return map.containsKey(o);&#125; isEmpty12345678/** * 判断HashSet是否是空的 * * @return &lt;tt&gt;true&lt;/tt&gt; if this set contains no elements */public boolean isEmpty() &#123; return map.isEmpty();&#125; 底层调用的是HashMap的isEmpty方法，实现如下 123public boolean isEmpty() &#123; return size == 0;&#125; ArrayList和HashSet的区别比较ArrayList和HashSet的区别，其实也是比较ArrayList和HashMap的区别 ArraysList是有序的，元素可以重复。HashSet无序，元素不可重复。 ArrayList底层是一个数组，HashSet底层是一个HashMap，HashMap的底层又是数组+链表+红黑树 ArrList在数组被填充满之后才会扩容，扩容到原来的1.5倍+1.HashSet和HashMap一样，扩容的实际和加载因子有关，扩容到原来的2倍 总结 HashSet的底层其实是一个HashMap，key是我们存放的元素，其value是一个final修饰的object对象 HashSet是无序的，和HashMap一样。 HashSet也是线程不安全的，我们可以使用Set s = Collections.synchronizedSet（new HashSet（…））包装一个线程安全的Set HashSet中的元素不可重复，因为HashMap中的key不可重复，重复的key会覆盖其value。 参考https://docs.oracle.com/javase/8/docs/api/]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java集合之JDK1.8LinkedHashMap源码解析]]></title>
    <url>%2Fconsectetur%2Fmalesuada%2FJava%E9%9B%86%E5%90%88%E4%B9%8BJDK1.8LinkedHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[概览LinkedHashMap实现了Map接口继承至HashMap，它在HashMap的基础上，通过一条双向链表是插入顺序和访问顺序保持一致。LinkedHashMap除了对双向链表的维护外，基本都是对HashMap的操作，所以在看LinkedHashMap源码之前，强烈建议先看看HashMap的源码,可以参考我的这一篇： 本篇文章不会再详细解析HashMap的东西，将重点放在LinkedHashMap对双向链表的维护上。 构造函数照例从创建LinkedHashMap对象说起，依次为起点，一步步解开LinkedHashMap的神秘面纱。 12345678910 LinkedHashMap() 使用默认初始容量16和默认加载因子0.75创建一个LinkedHashMap LinkedHashMap(int initialCapacity) 使用自定义初始容量和默认加载因子0.75创建一个LinkedHashMap LinkedHashMap(int initialCapacity, float loadFactor) 使用自定义初始容量和自动以加载因子创建一个LinkedHashMap LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) 使用自定义初始容量和自动以加载因子创建一个LinkedHashMap,并且可以设置accessOrder,accessOrder为true，调用get方法会改变内部结构，这一点后面会细讲 LinkedHashMap(Map&lt;? extends K,? extends V&gt; m) 使用Map子类实例创建一个LinkedHashMap LinkedHashMap() 无参构造123456public LinkedHashMap() &#123; //调用父类HashMap构造方法 super(); //accessOrder默认为false accessOrder = false;&#125; LinkedHashMap(int initialCapacity, float loadFactor)自定义初始容量和加载因子123456public LinkedHashMap(int initialCapacity, float loadFactor) &#123; //调用父类HashMap构造方法 super(initialCapacity, loadFactor); //accessOrder默认为false accessOrder = false;&#125; LinkedHashMap和HashMap的构造方法差不多，区别在于多了一个accessOrder，接下来看看这个字段起什么作用。 accessOrder点开accessOrder的调用处，发现除了构造方法外，只有3处使用了accessOrder字段,分别是get()方法,getOrDefault()方法和afterNodeAccess（）方法。 get()方法我们比较熟悉，先看下get()方法的代码 123456789public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; //如果accessOrder为true，调用afterNodeAccess()方法,传入get()方法取出的节点e if (accessOrder) afterNodeAccess(e); return e.value;&#125; 看下afterNodeAccess()方法的代码 12345678910111213141516171819202122232425262728void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last //声明最后一个节点last LinkedHashMap.Entry&lt;K,V&gt; last; //如果accessOrder为true并且最后一个节点tail不等于get()方法取出的节点e if (accessOrder &amp;&amp; (last = tail) != e) &#123; //将e复制给p,取出p的前节点和后节点分别复制给b和a LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; //将p的后节点置为null p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; tail是LinkedHashMap的成员变量,保存的是一份最新的节点数据。1234/** * The tail (youngest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; tail; 有最新的便有最老的，LinkedHashMap中使用head变量保存。1234/** * The head (eldest) of the doubly linked list. */transient LinkedHashMap.Entry&lt;K,V&gt; head; 这个方法的代码并不复杂，不一一解释了，我么只需要知道最终的效果是将get()方法取出的节点，放到了链表的最后，使之成为尾部节点，从而改变了数据在LinkedHashMap中的存储顺序，它的迭代顺序就是最后访问其条目的顺序。这种特性很适合构建LRU Cache LRU Cache什么是LRU？LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。 实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序。 位于链表尾部的元素就是不被重用的元素，所以会被踢掉。位于表头的元素就是最近刚刚被人用过的元素，所以暂时不会被踢。 看了这里的描述，有人可能会疑惑，链表尾部的元素会被踢掉。这和LinkedHashMap似乎正好矛盾，因为LinkedHashMap是将最近访问的元素放到末尾。 注意，链表的双向的，头部和尾部的确定取决于我们代码的上下文。 拓展:Redis在内存过高的时候可以对key进行淘汰，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。 这几种策略的其中之一便有LRU： volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 put()方法LinkedHashMap的put()方法继承至HashMap,没有进行重写。此处不再赘述HashMap的put()方法。LinkedHashMap对创建节点的方法进行了重写 new Node()重写12345678Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; //创建一个LinkedHashMap.Entry对象 LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); //将p放到链表的最后 linkNodeLast(p); return p;&#125; LinkedHashMap.Entry是LinkedHashMap的静态内部类，它就是所谓的双向链表,继承至HashMap.Node类，并在此基础上扩展了两个属性:前节点和后节点 12345678910/** * HashMap.Node subclass for normal LinkedHashMap entries. */static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; //定义了两个变量，分别是当前节点的前一个节点和后一个节点 Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 接下来看下linkNodeLast的代码 123456789101112//将tail保存一份LinkedHashMap.Entry&lt;K,V&gt; last = tail;//将最新的节点p赋值给tailtail = p;if (last == null) //如果链表是空的，将p放在链表头部 head = p;else &#123; //如果链表不为空，将p放到链表的尾部 p.before = last; last.after = p;&#125; get()方法LinkedHashMap对HashMap的get()方法进行了重写，区别在前面已经说过，主要就是accessOrder字段。如果我们设置了accessOrder字段为true，那么get()方法在获得数据之后，会将该数据节点放置链表的最后。 123456789public V get(Object key) &#123; Node&lt;K,V&gt; e; //调用HashMap的getNode()方法获取数据 if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value;&#125; remove()方法对于remove方法，在LinkedHashMap中也没有重写，它调用的还是父类的HashMap的remove()方法，在LinkedHashMap中重写的是：afterNodeRemoval(Node&lt;K,V&gt; e)这个方法，在Hash表的元素被删除之后，删除双向链表的元素。 12345678910111213void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125; Iterator遍历LinkedHashMap重写了entrySet()方法1234public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;&#125; LinkedHashMap实际上是对双向链表LinkedHashMap.Entry遍历。123456789101112131415161718192021222324252627282930313233343536373839abstract class LinkedHashIterator &#123; LinkedHashMap.Entry&lt;K,V&gt; next; LinkedHashMap.Entry&lt;K,V&gt; current; int expectedModCount; LinkedHashIterator() &#123; next = head; expectedModCount = modCount; current = null; &#125; public final boolean hasNext() &#123; return next != null; &#125; final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123; //遍历双向链表 LinkedHashMap.Entry&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); current = e; next = e.after; return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125;&#125; 总结 LinkedHashMap通过在HashMap的基础上增加一条双向链表，实现了插入顺序和访问顺序一致。实现的核心是静态内部类LinkedHashMap.Entry，LinkedHashMap.Entry继承至HashMap的静态内部类HashMap.Node。Entry拥有Node的所有属性，并且在此基础上增加了前节点和后节点两个属性。所有对底层HashMap数据结构修改的地方都会修改该链表进行修改,遍历的时候便是遍历这一条有序的链表。需要注意的是get()方法在accessOrder为true的时候也会对底层结构进行修改。 基于get()在accessOrder为true时，会将访问到的元素放到链表的最后的特性，我们可以使用LinkedHashMap实现LRU缓存。 LinkedHashMap同HashMap一样，线程不安全]]></content>
      <categories>
        <category>consectetur</category>
        <category>malesuada</category>
      </categories>
      <tags>
        <tag>semper</tag>
        <tag>fermentum</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Funcategorized%2FSharding-JDBC%E7%B3%BB%E5%88%97%E4%B9%8BSpringboot2%E4%B8%AD%E4%BD%BF%E7%94%A8Shariding-JDBC%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2Findex.html</url>
    <content type="text"><![CDATA[最近在工作中使用Sharding-JDBC做了分库分表，目前项目已经上线并稳定运行，闲暇时于记录下使用过程以及踩过的坑，希望对准备使用Sharding-JDBC做分库分表的同学有些帮助。 业务背景随着业务的发展，数据量也是爆炸式的增长，有的表结构数据量已经过亿，并且以每月几百万的量持续增长。已经到了必须分库分表的地步。正好我们的系统也要进行服务拆分，一个服务拆分为四个服务，于是一起将分库分表也做掉了。 技术选型在决定分库分表之后，首先要做的便是技术选型，目前市面上用来分库分表的中间件有很多，比如Mycat、Sharding-JDBC、淘宝的TDDL（未开源）、平明软件的OneProxy（收费）、360的Atlas、Youtube的Vitess，还有最近比较流行的TiDB等等。 在选择中间件之前，首先得了解分库分表中间件的切入时机 1.编码层 在同一个项目中创建多个数据源，采用if else的方式，直接根据条件在代码中路由。 缺点： 1.编写大量代码 2.代码无法公用 2.框架层 适合公司ORM框架统一的情况，通过修改或增强现有ORM框架的功能来实现 3.驱动层 重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。例如：Sharding-JDBC、TDDL等 4.代理层 伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。例如MyCat、MySQL Router、Sharding-Proxy 5.实现层更换底层的数据存储，比如Mysql替换为TiDB。 传统的分库分表，通常是在驱动层和代理层做切入，这两个各有优劣，不过在将驱动层和代理层的区别前，先说一下TiDB。 TiDBTiDB是公司一位大佬推荐的，了解一番后发现这个数据库很方便快捷的帮我们解决海量数据存储这件事情，如果能用TiDB代替传统的分库分表方案也是很好的，可以节省很多时间。不过由于这个数据库只在公司大数据部门的OLAP系统有应用，而实时性要求较高的OLTP系统目前还没有应用，所以决定对TiDB系统进行一次压测，看看其能否满足线上的要求。 压测的过程不多赘述，最终的结果页不是很理想，因为有这么一个怪现象：在持续高并发的情况下，会出现莫名其妙的连接超时失败。 对于这一结果，我们百思不得其解，对结果的准确性也保持的怀疑的态度。但是由于时间有限，不允许我们继续测试，只得将目光投向了其他中间件，同时也和官方联系，询问原因。 后面官方给出的说法是这样的：由于我们的内存配置的太小(8g)，导致持续 高并发的时候会进行内存回收，这个时候会强制断开连接。并且给我们介绍说目前实现上OLTP系统中应用TiDB内存都是258g，集群3台机器以上。好吧，都是土豪，惹不起。 Sharding-JDBC和Mycat排序TiDB后，便只能使用传统的分库分表方案，国内比较火的便是Sharding-JDBC和Mycat，这两个正是驱动层和代理层的代表。 相对于Mycat，仅仅是一个Jar包的Sharding-JDBC赢了我的青睐。 Sharding-JDBC在SpringBoot2中的应用。Sharidng-JDBC最早起源于当当，后来进入了Apache孵化器，变为了Sharding-Sphere，目前最新的版本是4.0.0-RC1。 依赖引入官方的文档并没有写明白Springboot项目应该如何引入依赖，好在机智的我在官方案例中找到了。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC1&lt;/version&gt;&lt;/dependency&gt; 配置数据源以及分库分表规则12345678910111213141516171819202122232425262728293031323334spring: shardingsphere: datasource: master0: # 主库连接信息 driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://$&#123;your database ip&#125;:3306/$&#123;your database name&#125;?Unicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true password: your password type: com.zaxxer.hikari.HikariDataSource username: your username master0slave0: # 从库连接信息 driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://$&#123;your database ip&#125;:3306/$&#123;your database name&#125;?Unicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true password: your password type: com.zaxxer.hikari.HikariDataSource username: your username names: master0,master0slave0 # 连接名称，和上面对应。如果有多个主库则配置master1,master1slave1，名字可以随便起，对应起来就好 sharding: broadcast-tables: # 配置广播表，适合数据量不大，但是每个数据源都存在的表 - xtgy_chaxunympz default-data-source-name: master0 #默认数据源，没有配置分库分表规则的表，会使用默认数据源 master-slave-rules: #配置主从规则 master0: master-data-source-name: master0 slave-data-source-names: master0slave0 tables: #配置各表的路由规则 table_name: #表名 actual-data-nodes: master0.table_name_$-&gt;&#123;0..127&#125; #实际表名 table_name_0 至 table_name_127 key-generator: #主键生成策略 column: id type: UUID table-strategy: #分表规则 inline: algorithm-expression: table_name_$-&gt;&#123;customer_id % 128&#125; #customer_id %128 sharding-column: customer_id #用于分表的键 允许Bean覆盖SpringBoot2默认不允许Bean覆盖，我们需要改成允许，不然可能会报错 123spring: main: allow-bean-definition-overriding: true 到这里，配置便完成了，是不是很简单？如果你的数据库和表结构都已经创建，就可以开始体验了。后面会介绍Sharding-JDBC的一些特性，已经源码解析。 参考https://shardingsphere.apache.org/document/current/cn/overview/ https://segmentfault.com/a/1190000017272697]]></content>
  </entry>
  <entry>
    <title><![CDATA[Lorem ipsum]]></title>
    <url>%2Fconsectetur%2Fmalesuada%2FTODO%EF%BC%9ARedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%AF%A6%E8%A7%A3%2Findex.html</url>
    <content type="text"><![CDATA[Lorem ipsumLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eu tempor dolor. Nulla hendrerit convallis purus et elementum. Suspendisse non magna vel justo tincidunt finibus. Nullam dui erat, malesuada eget viverra non, finibus a nisl.]]></content>
      <categories>
        <category>consectetur</category>
        <category>malesuada</category>
      </categories>
      <tags>
        <tag>semper</tag>
        <tag>fermentum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sharding-JDBC源码解析]]></title>
    <url>%2FSharding-JDBC%2FTODO%EF%BC%9ASharding-JDBC%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[最近在工作中使用Sharding-JDBC做了分库分表，目前项目已经上线稳定运行，闲暇之余看下源码。 版本:4.0.0-RC1 由于现在基本都是springboot，而Sharding-Sphere也提供了SpringBoot的包，所以先看看sharding-jdbc-spring-boot-starter的源码，maven坐标: org.apache.shardingsphere sharding-jdbc-spring-boot-starter ${sharding-sphere.version} &lt;sharding-sphere.version&gt;4.0.0-RC1&lt;/sharding-sphere.version&gt;]]></content>
      <categories>
        <category>Sharding-JDBC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java面试宝典]]></title>
    <url>%2F%E9%9D%A2%E8%AF%95%2Fjava%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8%2Findex.html</url>
    <content type="text"><![CDATA[前言 做好面试前的准备工作第一部分 Java基础关键字staticstatic 关键字的作用?static关键字可以让我们在不创建对象的情况下访问方法或变量。static除了可以修饰方法和变量外，还有static代码块，以及修饰内部类。被static修饰的数据，在内存中只会存在一份。合理利用static合理提升程序性能 静态变量 static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。 static成员变量的初始化顺序按照定义的顺序进行初始化。 静态方法 static方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。 静态代码块 static代码块在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。 为什么不能通过this访问static变量或者方法？this代表的是当前对象，被static修饰的变量或者方法，在类被加载的时候就会初始化，这个时候还没有创建对象。 static笔试题1234567891011121314151617181920212223242526public class StaticDemo extends ParentStaticDemo &#123; static &#123; System.out.println("static block run"); &#125; public StaticDemo() &#123; System.out.println("child constructor run"); &#125; public static void main(String[] args) &#123; new StaticDemo(); &#125;&#125;class ParentStaticDemo &#123; static &#123; System.out.println("parent static block run "); &#125; public ParentStaticDemo() &#123; System.out.println("parent constructor run"); &#125;&#125; 执行StaticDemo类的main()方法，输出顺序是怎样的？ 答案： parent static block run static block run parent constructor run child constructor run 在main()方法中，使用new StaticDemo()创建一个StaticDemo对象，但是在创建对象前需要先加载StaticDemo类，由于StaticDemo继承ParentStaticDemo，所以需要先加载ParentStaticDemo类，所以先执行的是”parent static block run “。加载完ParentStaticDemo后，开始加载StaticDemo，所以下一个输出的是static block run。StaticDemo加载完之后，开始创建StaticDemo，由于继承ParentStaticDemo，先执行父类的构造方法，所以先输出parent constructor run，最后是child constructor run。 finalfinal 通常表示无法被改变，在java中，final可以修饰变量、方法和类。 final变量 对于基本类型，final使数值恒定不变，而对于对象引用，final使引用恒定不变，一旦引用被初始化指向一个对象，就无法在将它指向另外一个变量。然而，对象其自身是可以修改的。 final方法 使用final方法的原因有两个，一是将方法锁定，确保在继承中是方法行为保持不变，不会被覆盖。二是效率。 在Java早期实现中，将一个方法指明为final，就是同意编译器将针对该方法的所有调用都改为内嵌调用。当编译器发现一个final方法调用命令时，它会跳过插入程序代码这种正常方式而执行方法调用机制(将参数调入栈，跳至方法方法代码处并执行，然后跳回并清理栈中的参数，处理返回值)，并且以方法体中的实际代码的副本来代替方法调用。这可以消除方法调用的开销。当然，如果一个方法很大，你的程序代码就会膨胀，所带来的性能提高会因为花费与方法内的时间量而被缩减。 需要注意的，JDK5以后，已经不推荐因为效率而使用final修饰方法，因为早期的虚拟机能够自动优化这种情况，只有你想明确禁止方法被覆盖时，才需要考虑使用final修饰方法。 final类 当将某个类定义为final类时，表名该类不能被集成。 transient在对象序列化的时候，有些变量不需要序列化，比如密码等，可以使用transient关键字来解决这个问题，transient修饰的变量不会被序列化。 volatilevolatile关键字的作用以及原理 synchronized其他String,StringBuffer和StringBuilder的区别；String不可变得，对String类型进行改变的时候其实都是生成了一个新的String对象，然后将引用指向新的string对象。 StringBuffer对象是线程安全的可变字符序列。常用的方法是append和insert，append是添加到末端，insert是在指定的点添加字符。StringBuffer的方法基本都是同步的。 StringBuilder是5.0新增的，和StringBufer差不多，但是是线程不安全的，大多数实现中，比StringBuffer要快。 Object的方法有哪些1、clone()2、equals()3、finalize()4、getclass()5、hashcode()6、notify()7、notifyAll()8、toString()9、wait() 集合ArrayList说一下ArrayList的源码 Fail-fast行为是什么？ArrayList里面有一个modCount属性，并且在其内部有一个私有的Itr类，实现了Iterator接口。在对ArrayList遍历时，首先会将modCount变量保存一份，之后每次遍历都会checkmodCount是否被修改了，如果修改了，则立即抛出ConcurrentModificationException List和Set的区别set接口规定其实现无序，不可重复。 HashSet（底层是HashMap） LinkedHashSetlist接口规定其实现有序，可重复。 实现类有：LinkedList，ArrayList，Vectormap接口是散列集合的顶层接口，存储的key-value键值对 HashMap HashTable StoredMap HashMap说一下HashMapde 源码HashMap源码解析 如何实现HashMap顺序存储：可以参考LinkedHashMap的底层实现；concurrentHashMap的源码解析多线程wait和sleep的区别，必须理解；说说阻塞队列的实现：可以参考ArrayBlockingQueue的底层实现（锁和同步都行）；进程通讯的方式：消息队列，共享内存，信号量，socket通讯等；用过并发包的哪些类；什么地方用了多线程；Excutors可以产生哪些线程池；为什么要用线程池；volatile关键字的用法：使多线程中的变量可见；Java中的多线程了解么，线程池的增长策略和拒绝策略了解么，说一下。讲一下线程增加的过程和拒绝策略的执行。讲了一下fixthreadpool的增长策略，然后几种拒绝策略。高并发情况下，如何使用线程池，用哪个，问了一下线程结束要多久，是否在下一个线程结束前完成（我想的是cachethreadpool，其实思路错了）。表示并发量比较大，所以我说可以考虑并发量是否大于队列长度加上最大线程数量和，如果不超过的话可以是用fixthreadpool。你在项目中怎么用到并发的IObio，nio，aio的区别；京东内部的jsf是使用的什么协议通讯：可参见dubbo的协议；反射和动态代理第二部分 常用框架spinrgmvcspringmvc的核心是什么，请求的流程是怎么处理的，控制反转怎么实现的；spring里面的aop的原理是什么；Springmvc的基本架构，请求流程。springSpring bean的生命周期说一下Spring源码把，它的架构，流程。Spring的bean如果要在实例化过程中修改其某一个成员变量，应该怎么做呢。不通过构造方法，并且AOP也并不能实现。mybatismybatis如何处理结果集：反射，建议看看源码；springbootdubbonio框架：dubbo的实现原理；shirosolr和es倒排索引zookeeperzookeeper是什么；zookeeper哪里用到；zookeeper的选主过程；zookeeper集群之间如何通讯；你们的zookeeper的节点加密是用的什么方式；分布式锁的实现过程；mavenMQmq的原理是什么：有点大。。都可以说；mq如何保证实时性；mq的持久化是怎么做的；第三部分 数据库mysqlmsyql优化经验：mysql的语句优化，使用什么工具；mysql的索引分类：B+，hash；什么情况用什么索引；mysql的存储引擎有哪些，区别是什么；说说事务的特性和隔离级别；悲观锁和乐观锁的区别，怎么实现；索引什么时候会失效变成全表扫描数据库的事务有什么用数据的索引有什么用，怎么实现联合索引的匹配原则数据库万级变成亿级，怎么处理。分库分表，分片规则hash和取余数。使用mycat中间件实现。https://mp.weixin.qq.com/s/ZtuUg79OFLh20-HWs2Qs4Aredisredis有哪些数据结构？介绍下zset，它底层原理是什么？布隆过滤器和hyperloglog.ip地址过滤的布隆过滤器实现。亿级ip地址过滤redis哨兵redis是怎么保证高可用的？redis为什么是单线程？redis的淘汰策略有哪些；mongodbdocker听说你项目用过docker，讲一下docker的实现原理，说了虚拟机一般要对内核进行虚拟化，docker则用cgroup和namespace分别进行硬件和命名空间的隔离。第四部分 Java虚拟机JVM的内存结构，JVM的算法；强引用，软引用和弱引用的区别；数组在内存中如何分配；请写一段栈溢出、堆溢出的代码；ThreadLocal可以用来共享数据吗；第五部分 JavaWebtomcat你平时是如何进行Tomcat性能优化的?你说了解Tomcat的基本原理，了解的是哪一部分，基本架构，connector和containerTomcat的类加载器了解么，回答不了解只了解Java的类加载器。web说说http,https协议；tcp/ip协议簇；osi五层网络协议；tcp，udp区别；用过哪些加密算法：对称加密，非对称加密算法；说说tcp三次握手，四次挥手；cookie和session的区别，分布式环境怎么保存用户状态；分布式session解决方案HTTP协议了解么，和tcp有什么区别。http1.0和2.0的区别。答了TCP连接复用，加入ssl，以及压缩请求头。web请求的过程，讲了浏览器到http服务器的过程，再讲了mvc的请求处理过程。其中哪个更新比较有意义，为什么。我说的是压缩请求头，这样可以优化HTTP服务的性能。 第六部分 设计模式第七部分 项目相关第八部分 算法相关java中常说的堆和栈，分别是什么数据结构；另外，为什么要分为堆和栈来存储数据。TreeMap如何插入数据：二叉树的左旋，右旋，双旋；一个排序之后的数组，插入数据，可以使用什么方法？答：二分法；问：时间复杂度是多少？平衡二叉树的时间复杂度；Hash算法和二叉树算法分别什么时候用；图的广度优先算法和深度优先算法：详见jvm中垃圾回收实现；排序算法和适用场景第九部分 Linuxlinux常用的命令有哪些；如何获取java进程的pid；如何获取某个进程的网络端口号；如何实时打印日志；如何统计某个字符串行数；第十部分 设计与思想重构过代码没有？说说经验；一千万的用户实时排名如何实现；五万人并发抢票怎么实现；项目中遇到的最大挑战。项目中学到最多的东西你的职业规划第十一部分 HR面试兴趣爱好三年到五年的职业规划意向公司和城市实习经历和收获实习中最大的困难为什么换公司，为什么拒绝菜鸟实习offer你的缺点和优点你觉得你比其他人优秀的地方说三个为什么想来我们部门]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[事务特性以及Mysql事务的实现]]></title>
    <url>%2Fmysql%2FTODO%EF%BC%9A%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%E4%BB%A5%E5%8F%8AMysql%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0%2Findex.html</url>
    <content type="text"><![CDATA[事务特性事务是数据库区别于文件系统的重要特征之一。事务用来保证数据库的完整性–要么都做修改，要么都不做。同时，事务有严格的定义，它必须同时满足四个特性。 原子性 原子性是指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作执行都成功，才算整个事务成功。如果事务中任何一个SQL语句执行失败，那么已经执行 成功的SQL语句也必须撒销，数据库状态应该退回到执行事务前的状态。 一致性(consistency) 一致性指事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务 结束以后，数据库的完整性约束没有被破坏。 隔离性(isolation) 一个事务的影响在该事务提交前对其他事务都不可见——这通过锁来实现 持久性(durability) 事务一旦提交，其结果就是永久性的。即使发生宕机等故障，数据库也能将数据恢复。 事务隔离级别了解事务隔离级别前，先介绍下数据库在并发读取数据产生的问题。 脏读 一个事务可以读到了另外一个还没有提交（commit）事务的数据。 举个例子： 公司发工资了，把50000元打到我的账号上，但是该事务并未提交，而我正好去查看账户，发现工资已经到账，是50000元整，非常高兴。可是不幸的是，领导发现发给的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后我实际的工资只有2000元，空欢喜一场。 脏读是两个并发的事务，“事务A：领导发工资”、“事务B：我查询工资账户”，事务B读取了事务A尚未提交的数据。 不可重复读 一个事务A需要多次读取一个数据，在这个事务还没有提交前，存在另外的事务B对改数据进行了修改，导致事务A前后读取的数据不一致。 幻读 事务A需要修改表中的所有数据行，与此同时，事务B需要往表中插入新的数据。事务A在修改完毕后发现还有数据没有被修改，就好象发生了幻觉一样。 ISO和ANIS SQL标准制定了四种事务隔离级别。 READ UNCOMMITTED在这一隔离级别，一个事务可以读到另外一个还没有提交（commit）的事务。脏读，不可重复度，幻读都有可能发生。 READ COMMITTED 该级别比READ UNCOMMITTED高一级，只能读取到事务已经提交的数据，它解决了脏读的问题，但是不能解决不可重复度，幻读。它是Oracle数据库的默认隔离级别。 REPEATABLE READ SERIALIZABLE READ UNCOMMITTED称为浏览访问(browse access),仅仅只对事务而言的。READ COMMITTED称为游标稳定(cursor stability)。REPEATABLE READ是2.9999°的 隔离，没有幻读的保护。SERIALIZABLE称为隔离，或3’。SQL和SQL 2标准的默认事务 隔离级别是SERIALIZABLE。 InnoDB存储引擎默认的支持隔离级别是REPEATABLE READ,但是与标准SQL不同 的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock锁的 算法，因此避免幻读的产生。这与其他数据库系统(如Microsoft SQL Server数据库)是不 同的。所以说，InnoDB存储引擎在默认REPEATABLE READ的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。 隔离级别越低，事务请求的锁越少，或者保持锁的时间就越短。这也是为什么大多数 数据库系统默认的事务隔离级别是READ COMMITTED。 Mysql事务的实现在Mysql中原子性、一致性、持久性通过数据库的redo和undo 来完成。隔离性用锁实现。 隔离性的实现隔离性由第6章讲述的锁得以实现。7.2.1 redo在InnoDB存储引擎中，事务日志通过重做(redo)日志文件和InnoDB存储引擎的日志 缓冲(InnoDB Log Buffer)来实现。当开始一个事务时，会记录该事务的一个LSN (LogSequence Number,日志序列号)，当事务执行时，会往InnoDB存储引擎的日志缓冲里插入事务日志I当事务提交时，必须将InnoDB存储引擎的日志缓冲写入磁盘(默认的实现， 即innodb_flush_log_at_trx_commit= 1)。也就是在写数据前，需要先写日志。这种方式称 为预写日志方式(Write-Ahead Logging, WAL)。InnoDB存储引擎通过预写日志的方式来保证事务的完整性。这意味着磁盘上存储的数据页和内存缓冲池中的页是不同步的，对于内存缓冲池中页的修改，先是写入重做日志文件，然后再写入磁盘，因此是一种异步的方式。可以通过命令SHOW ENGINE INNODB STATUS来观察当前磁盘和日志的“差距”：create table z (a int,primary key(a))engine-innodb; create procedure load_test (count int)begindeclare i int unsigned default 0;start transaction;while i &lt; count doinsert into z select i;set i=i+l;end while;conunit;end;首先建立一张表z，然后建立一个往表z中导入数据的存储过程load_test0通过命令 SHOW ENGINE INNODB STATUS观察当前的重做日志情况：mysql&gt; show engine innodb status\G;……LOG 1 row in set (0.00 sec)Log sequence number表示当前的LSN, Log flushed up to表示刷新到重做日志文件的 LSN, Last checkpoint at表示刷新到磁盘的LSN。因为当前没有任何操作，所以这三者的 值是一样的。接着开始导入10 000条记录：mysql&gt;call load_test(10000);mysql&gt; show engine innodb status\G; 这次SHOW ENGINE INNODB STATUS的结果就不同了，Log sequence number的LSN为113047672789, Log flushed up to的LSN为113047672789, Last checkpoint at的LSN为 113047174608,可以把Log flushed up to和Last checkpoint at的差值498 181 (-486.5K)理 解为重做日志产生的增量(以字节为单位)。虽然在上面的例子中，Log sequence number和Log flushed up to的值是相等的，但是在实际的生产环境中，该值有可能是f同的。因为在一个事务中从日志缓冲刷新到重做日志文件，并不只是在事务提交时发生，每秒都会有从日志缓冲刷新到重做日志文件的动作(这部分内容我们在3.6.2小节已经讲解过了)。下面是一个生产环境下重做日志的信息：. mysql&gt; show engine innodb status\G; 1 row in set (0.00 sec)可以看到，在生产环境下Log sequence number% Log flushed up to% Last checkpoint at 三个值可能是不同的。7.2.2 undo重做日志记录了事务的行为，可以很好地通过其进行“重做”。但是事务有时还需要撤销，这时就需要undo。undo与redo正好相反，对于数据库进行修改时，数据库不但会产生redo,而且还会产生一定量的undo,即使你执行的事务或语句由于某种原因失败了，或者如果你用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。与redo不同的是，redo存放在重做日志文件中，undo存放在数据库内部的一 个特殊段(segment)中，这称为undo段(undo segment), undo段位于共享表空间内。可 以通过pyjnnodb_pagejnfo.py工具，来査看当前共享表空间中undo的数量：froot^xen-server -]# python py_innodb_page_info.py /usr/local/mysql/data/ibdatal Total number of page: 46208:Insert Buffer Free List: 13093Insert Buffer Bitmap: 3System Page: 5Transaction system Page: 1Freshly Allocated Page: 4579undo Log Page: 2222File Segment inode: 6B-tree Node: 26296 扩展描述页：2可以看到，当前的共享表空间ibdata 1内有2222个undo页。我们通常对于undo有这样的误解：undo用于将数据库物理地恢复到执行语句或事务之前样子——但事实并非如此。数据库只是逻辑地恢复到原来的样子，所有修改都被逻辑地取消，但是数据结构本身在回滚之后可能大不相同，因为在多用户并发系统中，可能会有数十、数百甚至数千个并发事务。数据库的主要任务就是协调对于数据记录的并发访问。如一个事务在修改当前一个页中某几条记录，但同时还有别的事务在对同一个页中另几条记录进行修改。因此，不能将个页回滚到事务开始的样子，因为这样会影响其他事务正 在进行的工作。例如：我们的事务执行了一个INSERT 10万条记录的SQL语句，这条语句可能会导致分配一个新的段，即表空间会增大。如果我们执行ROLLBACK时，会将插入的事务进行回滚，但是表空间的大小并不会因此而收缩。因此，当InnoDB存储引擎回滚时，它实际上做的是与先前相反的工作。对于每个INSERT, InnoDB存储引擎会完成一个DELETE；对于每个DELETE, InnoDB存储引擎会执行一个INSERT；对于每个UPDATE, InnoDB存储 引擎则会执行一个相反的UPDATE,将修改前的行放回去。Oracle和Microsoft SQL Server数据库都有内部的数据字典来观察当前undo的信息*InnoDB存储引擎在这方面做得还是不够的，所以DBA只能通过原理和经验来进行判断。 我写过一个补丁（patch）来扩展SHOW ENGINE INNODB STATUS命令的显示结果，可 以用来査看当前内存缓冲池中undo页的数量，如下代码所示。 可以看到，当前内存缓冲中有1个undo页。接着我们开启一个事务，执行插入10万条 记录的操作，需要注意的是，这并不进行提交操作：mysql&gt; create table t like order_line;Query OK, 0 rows affected (0.23 sec)mysql&gt; insert into t select * from order一line limit 100000;Query OK, 100000 rows affected (45.01 sec)Records: 100000 Duplicates: 0 Warnings: 0之后在另一个会话中执行命令SHOW ENGINE INNODB STATUS,可以看到之前的会 话产生的undo量： 1 row in set (12.38 sec)可以看到，此时undo页的数量变成了129,也就是说，刚才的一个事务大致产生了129个undo页。另外，即使对INSERT的事务进行了提交，我们在一段时间内还是可以看到内存中有129个undo页。这是因为，对于undo页的回收是在master thread中进行的，masterthread也不是每次回收所有的undo页。关于master thread的工作原理，我们在第2.3.1小节曾 介绍过。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码解析]]></title>
    <url>%2F%E9%9B%86%E5%90%88%2FHashMap%2FHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[哈希表（hash table）也叫散列表，是一种非常重要的数据结构，应用场景及其丰富，许多缓存技术（比如memcached）的核心其实就是在内存中维护一张大的哈希表，而HashMap的实现原理也常常出现在各类的面试题中，重要性可见一斑。本文会对java集合框架中的对应实现HashMap的实现原理进行讲解，然后会对JDK8的HashMap源码进行分析。 什么是哈希表在讨论哈希表之前，我们先大概了解下其他数据结构 数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) 线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n) 二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。 哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。 我们知道，数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，哈希表的主干就是数组。 比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。 存储位置 = f(关键字) 其中，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。举个例子，比如我们要在哈希表中执行插入操作： 哈希冲突 然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证 计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式。 JDK8中HashMap的实现原理在JDK1.8之前，HashMap采用数组+链表实现，即使用链表处理冲突，同一hash值的节点都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，HashMap采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 下图中代表jdk1.8之前的hashmap结构，左边部分即代表哈希表，也称为哈希数组，数组的每个元素都是一个单链表的头节点，链表是用来解决冲突的，如果不同的key映射到了数组的同一位置处，就将其放入单链表中。 jdk1.8之前的hashmap都采用上图的结构，都是基于一个数组和多个单链表，hash值冲突的时候，就将对应节点以链表的形式存储。如果在一个链表中查找其中一个节点时，将会花费O（n）的查找时间，会有很大的性能损失。到了jdk1.8，当同一个hash值的节点数不小于8时，不再采用单链表形式存储，而是采用红黑树，如下图所示。 JDK8 HashMap源码解析类注释翻译点开HashMap，迎面扑来的便是一大段关于HashMap的类注释，一个屏幕都放不下。 通过这些注释，我们可以对HashMap的特性有一个大致的了解，接下来先尝试翻译一下，翻译不对的地方欢迎留言指出。 HashMap是Map接口的实现类，它基于哈希表，提供了所有可选的map操作，并允许null的值和null键（HashMap类大致相当于Hashtable ，区别在于它是不同步的，并允许null）。这个类不保证map的顺序; 特别是，它不能保证顺序是一直保持不变的。 如果Hash函数能够很完美的分散各个元素到桶上，对于get和put这些基础操作，HashMap可以提供恒定的时间性能。遍历HashMap的时间与实例的容量（桶数）加上其大小（key-value数量）成比例。因此，如果迭代性能很重要，则不要将初始容量设置得太高（或负载因子太低）。 HashMap实例有两个影响其性能的参数： 初始容量和负载因子 。_容量_是哈希表中的桶数，初始容量是创建哈希表时的容量。 负载因子决定扩容前哈希表能达到多少容量。 当哈希表中的条目数超过加载因子和当前容量的乘积时，哈希表会被重新哈希(也就是说，内部数据结构被重建),容量扩充为之前的两倍。 默认加载因子（0.75）在时间和空间成本之间提供了良好的权衡。 大于0.75会减少空间开销，但会增加查询成本（HashMap类的大多数操作中，包括get和put）。 在设置其初始容量时，应考虑预期key-value数及其加载因子，以便最小化扩容次数。 如果初始容量大于最大条目数除以加载因子，则不会发生扩容操作。 如果一个HashMap实例要存放很多的key-value，在初始化的时候指定一个大的容量比扩容性能更好。如果很多key的HashCode()相同，肯定会导致HashMap性能降低。如果这些间是Comparable（可比较）的，这个类或许可以通过键之间的比较顺序来改善性能。 需要注意的是HashMap不是同步的，如果多个线程同时访问HashMap，并且至少有一个线程在对其结构进行修改，则必须在外部加上同步（结构修改是添加或删除一个或多个映射的任何操作;仅更改与实例已包含的键关联的值不是结构修改）。这通常通过在一个封装map的对象上加上同步来解决。如果不存在这样的对象，则map应该使用Collections.synchronizedMap方法进行转换。这一步最好在创建的时候就完成，防止出现意外之外的不同步访问。 1Map m = Collections.synchronizedMap(new HashMap(...)); 所有这个类的“集合视图方法(collection view methods)”返回的迭代器都是快速失败（ fail-fast）的：在迭代器创建之后，除了迭代器自己的remove方法之外，任何时候对map进行结构修改，迭代器都将抛出ConcurrentModificationException。因此，面对并发修改，迭代器会快速而干净地失败，而不是在不确定的时间冒着不确定的风险。 请注意，迭代器的快速失败行为无法阿紫存在不同步的并发修改时做出任何硬性保证。快速失败迭代器会尽最大努力抛出ConcurrentModificationException。因此，不要编写这个异常的程序：迭代器的快速失败行为应仅用于检测错误。 这个类是Java集合框架的一员 重要字段1234567891011//实际存储的key-value键值对的个数transient int size; //阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。HashMap在进行扩容时需要参考threshold，后面会详细谈到int threshold; //负载因子，代表了table的填充度有多少，默认是0.75final float loadFactor; //用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount; 构造方法1234567891011HashMap()创建一个初始容量为16，默认加载因子为0.75的空HashMapHashMap(int initialCapacity)创建一个默认加载因子为0.75，自定义容量的空HashMapHashMap(int initialCapacity, float loadFactor)创建一个自定义加载因子，自定义容量的空HashMapHashMap(Map&lt;? extends K , ? extends V&gt; m)使用与指定Map相同的映射构造一个新的HashMap HashMap有4个构造器，最后一个很少使用，这里就不讲了。其他构造器如果用户没有传入initialCapacity 或者loadFactor这两个参数，会使用默认值，initialCapacity默认为16，loadFactory默认为0.75。 1234567/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 可以看到，无参构造非常简单，只是对加载因子赋了默认值，这个时候HashmMap内部的数组其实还没有被初始化为null。对于使用无参构造创建的HashMap，会在第一次put的时候初始化数组，put方法后面会细讲。 123456789101112131415161718public HashMap(int initialCapacity, float loadFactor) &#123; //此处对传入的初始容量进行校验，最大不能超过MAXIMUM_CAPACITY = 1&lt;&lt;30(2^30) //如果初始容量&lt;0，直接抛异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); //初始容量最大不能超过MAXIMUM_CAPACITY = 1&lt;&lt;30(2^30) if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //如果加载因子&lt;0或者不是浮点数,抛异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); //对初始容量赋值 this.loadFactor = loadFactor; //对阔值赋值 this.threshold = tableSizeFor(initialCapacity);&#125; tableSizeFor()方法是JDK8出现了，它的作用是返回返回大于输入参数且最近的2的整数次幂的数。比如输入3，则返回4；输入5，则返回8。这里的算法很是巧妙，对于性能有很大提升，感兴趣可以看这篇博客Java8 HashMap之tableSizeFor 123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; put()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public V put(K key, V value) &#123; //首先对key进行了Hash，然后直接调用putVal()方法 return putVal(hash(key), key, value, false, true); &#125;/** * Implements Map.put and related methods * * @param hash 键的哈希值 * @param key 键 * @param value 值 * @param onlyIfAbsent 如果为true，不改变已经存在的值 * @param evict 如果为true，处于创建模式. * @return 值 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; //申明变量 tab:临时数组 p:数组中的节点 n:存放老的容量 i:tab数组的下表 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为null或者长度为0，进行初始化分配大小 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //(n - 1) &amp; hash 计算出下标，如果该位置为null 说明没有碰撞，将value封装为一个新的Node并赋值 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; //反之，碰撞了 Node&lt;K,V&gt; e; K k; //首先判断key是否存在，如果是，覆盖原来的值 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //判断是否为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //是链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //将next指向新的节点 p.next = newNode(hash, key, value, null); //binCount &gt;= TREEIFY_THRESHOLD - 1 binCount&gt;=7,链表长度为8时,转变为红黑树,结束循环 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //如果链表中已经存在该key，结束循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //将e赋值给p，此处没明白为什么，p变量后面没有在使用过 p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) ////根据规则选择是否覆盖value e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //fail-fast相关，迭代时会保存一份modCount，每次遍历都会比较该值和保存的值是否相等，不相等则抛出异常 ++modCount; //如果size &gt;阔值，扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; put()方法涉及的成员变量或成员方法 成员变量transient Node&lt;K,V&gt;[] tabletable是HashMap用来实际存放元素的数组，它在首次使用时会被初始化。它的长度始终是2的幂次方。在某些操作中长度可能为0。 1234/** * HashMap用来实际存放元素的数组 */transient Node&lt;K,V&gt;[] table; 成员变量阔值threshold123456/** * 触发扩容的值 (容量 * 加载因子). * * @serial */int threshold; 静态方法hash()12345static final int hash(Object key) &#123; int h; //先取key的hashCode,然后和其低16位进行异或操作 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 我们知道HashMap的容量是2的幂次方，那么newCap - 1的高位应该全部为0。如果e.hash值只用自身的hashcode的话，那么index只会和e.hash低位做&amp;操作。这样一来，index的值就只有低位参与运算，高位毫无存在感，从而会带来哈希冲突的风险。所以在计算key的哈希值的时候，用其自身hashcode值与其低16位做异或操作。这也就让高位参与到index的计算中来了，即降低了哈希冲突的风险又不会带来太大的性能问题。–出自掘金，作者：特立独行的猪手 方法resize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123; //保存一份老的数组 Node&lt;K,V&gt;[] oldTab = table; //老数组的容量，如果老数组为null，则是0，否则取length int oldCap = (oldTab == null) ? 0 : oldTab.length; //保存一份老的阔值 int oldThr = threshold; //初始化新的容量和阔值 int newCap, newThr = 0; //如果老的容量&gt;0 if (oldCap &gt; 0) &#123; //如果老的容量达到了最大值，不扩容，并且将阔值设置为了Integer的最大值2的31次方-1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125;else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //首先将老的容量*2赋值给新的容量，然后判断新的容量&lt;MAXIMUM_CAPACITY 并且老的容量大于16，将阔值*2 newThr = oldThr &lt;&lt; 1; // double threshold &#125;else if (oldThr &gt; 0) // 如果老的数组容量&lt;=0，但是阔值&gt;0，直接将阔值赋值给新的容量 newCap = oldThr; else &#123; // 初始化 //新的容量为DEFAULT_INITIAL_CAPACITY 16 newCap = DEFAULT_INITIAL_CAPACITY; //新的阔值为0.75 * 16 = 12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; //防止阔值为0，比较好奇这种情况什么时候会出现，知道的同学还请不吝赐教 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //将新的阔值赋值给成员变量 threshold = newThr; //下面是将创建一个新的Node数组，并将老的数组里面的元素赋值到新的数组，这里不详细解读了。 @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; get()1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 使用getNode()方法取值，没有返回null 12345678910111213141516171819202122232425final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //判断是否有元素，没有返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //每次都会check第一个元素是否命中，命中直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果有下一个元素 if ((e = first.next) != null) &#123; //如果是红黑树，从红黑树中取值 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //遍历链表，直到取到值 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; Node数据节点解析我们知道HashMap底层维护了一个Node数组，它是最基础的数据节点，接下来便揭开Node数组的神秘面纱。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 首先看它的类声明，实现了Map.Entry接口。Entry接口定义了一些Map实现类公用的方法 可以看到Node类其实非常简单，维护了四个属性 key、value、key的Hash值和下一个节点。我们看下是怎么用的。 上面的在put()方法中已经提到过，当我们put一个key-value时，如果key不存在，或者说没有发生哈希冲突时，就会new一个新的节点。 123...tab[i] = newNode(hash, key, value, null);... 看下newNode方法,非常简单就是调用了Node的构造函数 123Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next);&#125; 当发生hash碰撞的时候，首先是已链表的形式存放。实际上就是创建一个新的Node节点，然后复制给之前的Node元素的next属性。 12...p.next = newNode(hash, key, value, null); 当链表的长度大于8的时候，转化为红黑树,这个时候其实是把Node链表转变为另外一个数组结构ZreeNode。 1234...if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 将链表转换为红黑树 treeifyBin(tab, hash); 123456789101112131415161718192021222324/** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 限于篇幅，此处不深入讲解红黑树这种数据结构以及其实现，后面会单独开一篇讲。 HashMap的初始容量应该如何指定同ArrayList一样，我们在new Hashmap()的也最好能够指定它的初始容量大小，目的就是为了提升效率，也能在一定程度上节约内存，那么这个初始容量应该如何指定？看过源码后，相信应该已经知道答案。 在HashMap中有一个成员变量threshold,它的计算方式是初始容量*加载因子。当填充度大于threshold，则会进行扩容。所以如果我们在知道或者大致估计HashMap的存放数量之后，除以0.75，在选择大于此结果的最近的2的幂次方即可（这一步可忽略，因为HashMap会自动帮你完成）。 有的同学可能会有HashMap最小容量是16的错觉，其实并不是，16只是我们在没有指定初始容量后，第一次put元素时初始化的容量。我们完全可以将容量指定为2。 总结 JDK1.8之后HashMap底层是数组+链表+红黑树 HashMap线程不安全，我们可以使用Collections.synchronizedMap包装为线程安全HashMap或者使用HashTable，CurrentHashMap HashMap的默认初始容量为16，加载因子是0.75，填充度达到75%后，会扩容至原来的2倍 参考:https://juejin.im/post/5aa47ef2f265da23a0492cc8#heading-4https://juejin.im/post/58f2f47061ff4b0058f4b7cc#heading-7https://docs.oracle.com/javase/8/docs/api/]]></content>
      <categories>
        <category>集合</category>
        <category>HashMap</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
        <tag>list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java数据结构:树（Tree）]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2FJava%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%3ATree%2Findex.html</url>
    <content type="text"><![CDATA[Java数据结构:树（Tree）计算机科学中的树在计算机科学中，树（英语：tree）是一种抽象数据类型（ADT）或是实现这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n&gt;0）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点： 每个节点都只有有限个子节点或无子节点； 没有父节点的节点称为根节点； 每一个非根节点有且只有一个父节点； 除了根节点外，每个子节点可以分为多个不相交的子树； 树里面没有环路(cycle) 为什么需要树为什么要用到树呢？因为它通常结合了另外两种数据结构的优点：一种是有序数组，另一种是链表。在树中查找数据项的速度和在有序数组中查找一样快， 并且插入数据项和删除数据项的速度也和链表一样。下面，我们先来稍微思考一下这些话题，然后再深入地研究树的细节。 在有序数组中插入数据项太慢假设数组中的所有数据项都有序的排列—这就是有序数组，用二分查找法可以在有序数组中快速地查找特定的值。它的过程是先査看数组的正中间的数据项，如果那个数据项值比要找的大，就缩小査找范围，在数组的后半段中找；如果小， 就在前半段找。反复这个过程，查找数据所需的时间是O(logN)。同时也可以迅速地遍历有序数组， 按顺序访问每个数据项。 然而，想在有序数组中插入一个新数据项，就必须首先査找新数据项插入的位置，然后把所有比新数据项大的数据项向后移动一位，来给新数据项腾出空间。这样多次的移动很费时，’平均来讲要移动数组中一半的数据项(N/2次移动)。删除数据项也需要多次的移动，所以也很慢。显而易见，如果要做很多的插入和删除操作，就不该选用有序数组。 在链表中查找太慢链表的插入和删除操作都很快。它们只需要改变一些引用的值就行了。这些操作的时间复杂度是0(1)(是大O表示法中最小的时间复杂度)。 但是在链表中查找数据项可不那么容易。查找必须从头开始，依次访问链表中的每一个数据项，直到找到该数据项为止。因此，平均需要访问N/2个数据项，把每个数据项的值和要找的数据项做比较。这个过程很慢，费时O(N)(注意，对排序来说比较快的，对数据结构操作来说是比较慢的。)。 不难想到可以通过有序的链表来加快查找速度，链表中的数据项是有序的，但这样做是没有用的。即使是有序的链表还是必须从头开始依次访问数据项，因为链表中不能直接访问某个数据项，必须通过数据项间的链式引用才可以。（当然有序链表访问节点还是比无序链表快多了，但查找任意的数据项时它也无能为力了 o ） 术语 节点的度：一个节点含有的子树的个数称为该节点的度； 树的度：一棵树中，最大的节点度称为树的度； 叶节点或终端节点：度为零的节点； 非终端节点或分支节点：度不为零的节点； 父亲节点或父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点； 孩子节点或子节点：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点：具有相同父节点的节点互称为兄弟节点； 节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推； 深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0； 高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0； 堂兄弟节点：父节点在同一层的节点互为堂兄弟； 节点的祖先：从根到该节点所经分支上的所有节点； 子孙：以某节点为根的子树中任一节点都称为该节点的子孙。 森林：由m（m&gt;=0）棵互不相交的树的集合称为森林； 树的种类无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树； 二叉树：每个节点最多含有两个子树的树称为二叉树； 完全二叉树：对于一颗二叉树，假设其深度为d（d&gt;1）。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树； 满二叉树：所有叶节点都在最底层的完全二叉树； 平衡二叉树（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树； 排序二叉树(二叉查找树（英语：Binary Search Tree))：也称二叉搜索树、有序二叉树； 霍夫曼树：带权路径最短的二叉树称为哈夫曼树或最优二叉树； B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多于两个子树。 树的抽象（ADT）树作为一种抽象的数据类型，至少要支持以下的基本方法方法名 | 描述 |-|-|getElement() | ： 返回存放于当前节点处的对象|setElement(e) | 将对象 e 存入当前节点，并返回其中此前所存的内容|getParent() | 返回当前节点的父节点|getParent() | 返回当前节点的父节点|getFirstChild()|返回当前节点的长子 |getNextSibling() | 返回当前节点的最大弟弟 | 树的实现使用数组实现树可以使用数组实现，节点在数组中的位置对应于它在树中的位置。下标为0的节点是根，下标为1的节点是根的左子节点，依次类推，按从左到右的顺序存储树的每一层。 树中的每个位置，无论是否存在节点，都对应数组中的一个位置。把节点插入树的一个位置， 意味着要在数组的相应位置插入一个数据项。树中没有节点的位置在数组中的对应位置用0或null来表示。 基于这种思想，找节点的子节点和父节点可以利用简单的算术计算它们在数组中的索引值。设节点索引值为index,则节点的左子节点是：2index + 1 ,它的右子节点是2index + 2,它的父节点是（index-1） / 2 大多数情况下用数组表示树不是很有效率。不满的节点和删除掉的节点在数组中留下了洞，浪费存储空间。更坏的是，删除节点时需要移动子树的话，子树中的每个节点都要移到数组中新的位置去，这在比较大的树中是很费时的。 不过，如果不允许删除操作，数组表示可能会很有用，特别是因为某种原因要动态地为每个节点分配空间非常耗时。数组表示法在其他一些特殊的情况下也很有用。 使用链表实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * @author keji * @version : Tree.java, v 0.1 2019-07-18 9:46 keji Exp $$ */public interface Tree &#123; /** * 返回当前节点中存放的对象 * * @return Object */ Object getElem(); /** * 将对象obj存入当前节点，并返回此前的内容 * * @return Object */ Object setElem(Object obj); /** * 返回当前节点的父节点 * * @return TreeLinkedList */ TreeLinkedList getParent(); /** * 返回当前节点的长子 * * @return TreeLinkedList */ TreeLinkedList getFirstChild(); /** * 返回当前节点的最大弟弟 * * @return TreeLinkedList */ TreeLinkedList getNextSibling(); /** * 返回当前节点后代元素的数目，即以当前节点为根的子树的规模 * * @return int */ int getSize(); /** * 返回当前节点的高度 * * @return int */ int getHeight(); /** * 返回当前节点的深度 * * @return int */ int getDepth();&#125; 对应实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * @author keji * @version : TreeLinkedList.java, v 0.1 2019-07-18 9:46 keji Exp $$ */public class TreeLinkedList implements Tree &#123; /** * 树根节点 */ private Object element; /** * 父节点、长子及最大的弟弟 */ private TreeLinkedList parent, firstChild, nextSibling; /** * （单节点树）构造方法 */ public TreeLinkedList() &#123; this(null, null, null, null); &#125; /** * 构造方法 * * @param object 树根节点 * @param parent 父节点 * @param firstChild 长子 * @param nextSibling 最大的弟弟 */ public TreeLinkedList(Object object, TreeLinkedList parent, TreeLinkedList firstChild, TreeLinkedList nextSibling) &#123; this.element = object; this.parent = parent; this.firstChild = firstChild; this.nextSibling = nextSibling; &#125; @Override public Object getElem() &#123; return element; &#125; @Override public Object setElem(Object obj) &#123; Object bak = element; element = obj; return bak; &#125; @Override public TreeLinkedList getParent() &#123; return parent; &#125; @Override public TreeLinkedList getFirstChild() &#123; return firstChild; &#125; @Override public TreeLinkedList getNextSibling() &#123; return nextSibling; &#125; @Override public int getSize() &#123; //当前节点也是自己的后代 int size = 1; //从长子开始 TreeLinkedList subtree = firstChild; //依次 while (null != subtree) &#123; //累加 size += subtree.getSize(); //所有孩子的后代数目 subtree = subtree.getNextSibling(); &#125; //得到当前节点的后代总数 return size; &#125; @Override public int getHeight() &#123; int height = -1; //从长子开始 TreeLinkedList subtree = firstChild; while (null != subtree) &#123; //在所有孩子中取最大高度 height = Math.max(height, subtree.getHeight()); subtree = subtree.getNextSibling(); &#125; //即可得到当前节点的高度 return height + 1; &#125; @Override public int getDepth() &#123; int depth = 0; //从父亲开始 TreeLinkedList p = parent; while (null != p) &#123; depth++; //访问各个真祖先 p = p.getParent(); &#125; //真祖先的数目，即为当前节点的深度 return depth; &#125;&#125; 树的遍历所谓树的遍历（Traversal），就是按照某种次序访问树中的节点，且每个节点恰好访问一次。 也就是说，按照被访问的次序，可以得到由树中所有节点排成的一个序列。 前序遍历对任一（子）树的前序遍历，将首先访问其根节点，然后再递归地对其下的各棵子树进行前序遍历。对于同一根节点下的各棵子树，遍历的次序通常是任意的；但若换成有序树，则可以按照兄弟间相应的次序对它们实施遍历。由前序遍历生成的节点序列，称作前序遍历序列。 后续遍历对称地，对任一（子）树的后序遍历将首先递归地对根节点下的各棵子树进行后序遍历，最后才访问根节点。由后序遍历生成的节点序列，称作后序遍历序列。 层次遍历除了上述两种最常见的遍历算法，还有其它一些遍历算法，层次遍历（Traversal by level ）算法就是其中的一种。在这种遍历中，各节点被访问的次序取决于它们各自的深度，其策略可以总结为“深度小的节点优先访问”。对于同一深度的节点，访问的次序可以是随机的，通常取决于它们的存储次序，即首先访问由firstChild指定的长子，然后根据nextSibling确定后续节点的次序。当然，若是有序树，则同深度节点的访问次序将与有序树确定的次序一致。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java数据结构：二叉树与二叉搜索树]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2FJava%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9A%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%2Findex.html</url>
    <content type="text"><![CDATA[Java数据结构：二叉树与二叉搜索树上一篇介绍了树这种数据结构，并用Java代码使用链表实现了树。,接下来介绍树的其中一种特例，二叉树。 在计算机科学中，二叉树（英语：Binary tree）是每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构。通常分支被称作“左子树”或“右子树”。二叉树的分支具有左右次序，不能随意颠倒。 二叉树的第 层至多拥有 个节点；深度为 的二叉树至多总共有个节点（定义根节点所在深度 ），而总计拥有节点数匹配的，称为“满二叉树”；深度为 有个节点的二叉树，当且仅当其中的每一节点，都可以和同样深度的满二叉树，序号为1到的节点一对一对应时，称为完全二叉树。对任何一棵非空的二叉树，如果其叶片（终端节点）数为 ，分支度为2的节点数为 ，则 。 与普通树不同，普通树的节点个数至少为1，而二叉树的节点个数可以为0；普通树节点的最大分支度没有限制，而二叉树节点的最大分支度为2；普通树的节点无左、右次序之分，而二叉树的节点有左、右次序之分。 二叉树通常作为数据结构应用，典型用法是对节点定义一个标记函数，将一些值与每个节点相关系。这样标记的二叉树就可以实现二叉搜索树和二叉堆，并应用于高效率的搜索和排序。 二叉树的实现Node类首先，需要有一个节点对象的类。这些对象包含数据，数据代表要存储的内容（例如，在员工数据库中的员工记录），而且还有指向节点的两个子节点的引用。12345678910111213141516171819202122232425262728293031323334353637@Datapublic class Node&lt;T&gt; &#123; /** * 角标 */ private Integer index; /** * 数据 */ private T data; /** * 左节点 */ private Node leftChild; /** * 右节点 */ private Node rightChild; public void displayNode() &#123; &#125; /** * 构造函数 * * @param index 角标 * @param data 数据 */ public Node(Integer index, T data) &#123; this.index = index; this.data = data; this.leftChild = null; this.rightChild = null; &#125;&#125; 有些实现也把节点的父节点的引用包括在Node类中。这样做会使一些操作简化，但使一些别的操作复杂，所以这里不使用它。 这个类中还有一个叫displayNode()的方法，用它来显示节点数据，不过在这里没有写出它的代码。 Tree类还需要有一个表示树本身的类，由这个类实例化的对象含有所有的节点，这个类是Tree类。它只有一个数据字段：一个表示根的Node变量。它不需要包含其他节点的数据字段，因为其他节点都可以从根开始访问到。 Tree类有很多方法。它们用来查询、插入和删除节点；进行各种不同的遍历；显示树。下面是这个类的骨架:1234567891011121314151617public class Tree&lt;T&gt; &#123; private Node&lt;T&gt; root; public Node&lt;T&gt; find(int key) &#123; return null; &#125; public void insert(int id, T data) &#123; &#125; public Node delete(int id) &#123; return null; &#125;&#125; 遍历二叉树作为树的一种特例，二叉树自然继承了一般树结构的前序、后序以及层次等遍历方法。这三个遍历算法的实现与普通树大同小异，这里不再赘述。 需要特别指出的是，对二叉树还可以定义一个新的遍历方法⎯⎯中序遍历（Inorder traversal）。顾名思义，在访问每个节点之前，首先遍历其左子树；待该节点被访问过后，才遍历其右子树。类似地，由中序遍历确定的节点序列，称作中序遍历序列。 二叉搜索树（Binary Search Tree）二叉搜索树（英语：Binary Search Tree），也称为二叉查找树、有序二叉树（ordered binary tree）或排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低。为 。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树的查找过程和次优二叉树类似，通常采取二叉链表作为二叉查找树的存储结构。中序遍历二叉查找树可得到一个关键字的有序序列，一个无序序列可以通过构造一棵二叉查找树变成一个有序序列，构造树的过程即为对无序序列进行查找的过程。 每次插入的新的结点都是二叉查找树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的复杂度等于树高，期望 ，最坏 （数列有序，树退化成线性表）。 虽然二叉查找树的最坏效率是 ，但它支持动态查询，且有很多改进版的二叉查找树可以使树高为 ，从而将最坏效率降至 ，如AVL树、红黑树等。 在二叉搜索树插入节点的算法向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指节点作为根节点插入，否则： 若s-&gt;data等于b的根节点的数据域之值，则返回，否则： 若s-&gt;data小于b的根节点的数据域之值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中。（新插入节点总是叶子节点） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Tree&lt;T&gt; &#123; private Node&lt;T&gt; root; public Node&lt;T&gt; find(int key) &#123; return null; &#125; public void insert(int id, T data) &#123; Node&lt;T&gt; newNode = new Node&lt;&gt;(); newNode.setIndex(id); newNode.setData(data); if (null == root) &#123; root = newNode; &#125;else &#123; //从根节点开始查找 Node&lt;T&gt; current = root; //声明父节点的引用 Node&lt;T&gt; parent; while (true) &#123; //父节点的引用指向当前节点 parent = current; //如果角标小于当前节点,插入到左节点 if (id &lt; current.getIndex()) &#123; current = current.getLeftChild(); //节点为空才进行赋值，否则继续查找 if (null == current) &#123; parent.setLeftChild(newNode); return; &#125; &#125;else &#123; //否则插入到右节点 current = current.getRightChild(); if (null == current) &#123; parent.setRightChild(newNode); return; &#125; &#125; &#125; &#125; &#125; public Node delete(int id) &#123; return null; &#125;&#125; 二叉搜索树的查找算法在二叉搜索树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的数据域之值，则查找成功；否则： 若x小于b的根节点的数据域之值，则搜索左子树；否则： 查找右子树。 12345678910111213141516171819202122public Node&lt;T&gt; find(int key) &#123; if (null == root) &#123; return null; &#125; Node&lt;T&gt; current = root; //如果不是当前节点 while (current.getIndex() != key) &#123; if (key &lt; current.getIndex()) &#123; current = current.getLeftChild(); &#125;else &#123; current = current.getRightChild(); &#125; //如果左右节点均为null，查找失败 if (null == current) &#123; return null; &#125; &#125; return current;&#125; 在二叉查找树删除结点的算法删除节点是二叉搜索树常用的一般操作中最复杂的。但是，删除节点在很多树的应用中又非常重要，所以要详细研究并总结特点。 删除节点要从查找要删的节点开始入手，方法与前面介绍的find()和insert()相同。找到节点后,这个要删除的节点要分三种情况讨论： 该节点是叶节点(没有子节点)。 该节点有一个子节点。 该节点有两个子节点。 情况一：删除没有子节点的节点要删除叶节点，只需要改变该节点的父节点的对应子字段的值，由指向该节点、改为null就可以了。要删除的节点仍然存在，但它已经不是树的一部分了。 因为Java语言有垃圾自动收集的机制，所以不需要非得把节点本身给删掉。 情况二 删除只有一个子节点的节点第二种情况也不是很难。这个节点只有两个连接：连向父节点的和连向它惟一的子节点的。 需要从这个序列中“剪断”这个节点，把它的子节点直接连到它的父节点上。这个过程要求改变父节点适当的引用(左子节点还是右子节点)，指向要删除节点的子节点。 情况三 删除有两个子节点的节点下面有趣的情况出现了。如果要删除的节点有两个子节点，就不能只是用它的一个子节点代替它。为什么不能这样呢？看图： 假设要删除节点25,并且用它的根是35的右子树取代它。那么35的左子节点应该是谁呢？是要删除节点25的左子节点15,还是35原来的左子节点30？然而在这两种情况中30都会被放得不对，但又不能删掉它。 对每一个节点来说，比该节点的关键字值次高的节点是它的中序后继，可以简称为该节点的后继。在上图中，节点30就是节点25的后继。 这里有一个窍门：删除有两个子节点的节点，用它的中序后继来代替该节点。如下图： 这里还有更麻烦的情况是它的后继自己也有子节点，后面会讨论这种可能性。 找后继节点 怎么找节点的后继呢？算法如下: 首先，找到初始节点的右子节点A，它的关键字值一定比初始节点大。然后转到A的左子节点那里（如果有的话），然后到这个左子节点的左子节点，以此类推，顺着左子节点的路径一直向下找。这个路径上的最后一个左子节点就是初始节点的后继。 如果初始节点的右子节点没有左子节点，那么这个右子节点本身就是后继。 以下是找后继节点的代码:123456789101112131415161718192021222324private Node&lt;T&gt; getSuccessor(Node&lt;T&gt; delNode) &#123; Node&lt;T&gt; successorParent = delNode; Node&lt;T&gt; successor = delNode; //go to rightChild Node&lt;T&gt; current = delNode.getRightChild(); while (current != null) &#123; //一直往下找左节点 successorParent = successor; successor = current; current = current.getLeftChild(); &#125; //跳出循环，此时successor为最后的一个左节点，也就是被删除节点的后继节点 //这里的判断先忽视，在后面会讲 if (successor != delNode.getRightChild()) &#123; successorParent.setLeftChild(successor.getRightChild()); successor.setRightChild(delNode.getRightChild()); &#125; return successor;&#125; 这个方法首先找到delNode的右子节点，然后，在while循环中，顺着这个右子节点所有左子节点的路径向下查找。当while循环中止时，successor就存有delNode的后继。 找到后继后，还需要访问它的父节点，所以在while循环中还需要保留当前节点的父节点。 正如看到的那样，后继节点可能与current有两种位置关系，current就是要删除的节点。后继可能是current的右子节点，或者也可能是current右子节点的左子孙节点。下面来依次看看这两种情况。 后继节点是delNode的右子节点 如果后继是cunent的右子节点，情况就简单了一点，因为只需要把后继为根的子树移到删除的节点的位置。这个操作只需要两个步骤： 把current从它父节点的rightChild字段删掉(当然也可能是leftChild字段)，把这个字段指向后继。 把current的左子节点移出来，把它插到后继的leftChild字段。 下图演示了这种情况，要删除节点75，后继节点是其右节点 接上之前的代码123456789101112131415161718192021public Node&lt;T&gt; delete(int key) &#123; //...接前面的else if else &#123; //查找后继节点 Node&lt;T&gt; successor = getSuccessor(current); //情况3.1 如果如果删除节点有两个子节点且后继节点是删除节点的右子节点 if (current == root) &#123; root = successor; &#125; else if (isLeftChild) &#123; parent.setLeftChild(successor); &#125; else &#123; parent.setRightChild(successor); &#125; successor.setLeftChild(current.getLeftChild()); &#125; return current;&#125; 第一步：如果要删除的节点current是根，它没有父节点，所以就只需要把根置为后继。否则，要删除的节点或者是左子节点或者是右子节点了(图8.19中它是右子节点)，因此需要把它父节点的对应的字段指向successor。当delete()方法返回，current失去了作用范围后，就没有引用指向current保存的节点，它就会被Java的垃圾收集机制销毁。 第二步：把successor的左子节点指向的位置设为current的左子节点。 如果后继有子节点怎么办呢？首先，后继节点是肯定不会有左子节点的。无论后继是要删除节点的右子节点还是这个右子节点的左子节点之一，这条在查找后继节点的算法中可以验证。 另一方面，后继很有可能有右子节点。当后继是被删除节点的右子节点时，这种情况不会带来多大问题。移动后继的时候，它的右子树只要跟着移动就可以了。这和要删除节点的右子节点没有冲突，因为后继就是右子节点。 下面这种情况就需要很小心了。 后继节点是delNode右子节点的左后代 如果successor是要删除节点右子节点的左后代，执行删除操作需要以下四个步骤: 把后继父节点的leftChild字段置为successor的右子节点。 把successor的rightChild字段置为要删除节点的右子节点。 把current从它父节点的rightChild字段移除，把这个字段置为successor 把current的左子节点从current移除，successor的leftChild字段置为current的左子节点。 第1步和第2步由getSuccessor()方法完成(已经在前面写上了)，第3步和第4步由delete()方法完成。 通过标记删除看到这里，删除操作已经全部完成了，真的是相当棘手的操作，难就难在节点的改变上。那么我们可不可以不改变节点，达到删除的目的？。 答案是可以的，在node类中加了一个Boolean的字段，名称如deleted。要删除一个节点时，就把此节点的这个字段置为true。其他操作，像find(),在查找之前先判断这个节点是不是标志为已删除了。 这样，删除的节点不会改变树的结构。当然，这样做存储中还保留着这种“己经删除”的节点。 如果树中没有那么多删除操作时，这也不失为一个好方法。（例如，已经离职的员工的档案要永久保存在员工记录中。） 下面是删除操作的完整代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public Node&lt;T&gt; delete(int key) &#123; if (null == root) &#123; return null; &#125; Node&lt;T&gt; current = root; Node&lt;T&gt; parent = root; boolean isLeftChild = true; //删除操作第一步，查找要删除的节点 while (current.getIndex() != key) &#123; parent = current; if (key &lt; current.getIndex()) &#123; isLeftChild = true; current = current.getLeftChild(); &#125; else &#123; isLeftChild = false; current = current.getRightChild(); &#125; //如果左右节点均为null，没有找到要删除的元素 if (null == current) &#123; return null; &#125; &#125; //跳出循环，找到要删除的元素:current if (null == current.getLeftChild() &amp;&amp; null == current.getRightChild()) &#123; //情况1：如果当前节点没有子节点 if (current == root) &#123; //如果当前节点是根节点,将树清空 root = null; return current; &#125; else if (isLeftChild) &#123; //如果当前节点是其父节点的做节点，将父节点的左节点清空 parent.setLeftChild(null); &#125; else &#123; parent.setRightChild(null); &#125; &#125; else if (null == current.getRightChild()) &#123; //情况2.1：如果删除节点只有一个子节点且没有右节点 if (current == root) &#123; root = current.getLeftChild(); &#125; else if (isLeftChild) &#123; parent.setLeftChild(current.getLeftChild()); &#125; else &#123; parent.setRightChild(current.getLeftChild()); &#125; &#125; else if (null == current.getLeftChild()) &#123; //情况2.2 如果删除节点只有一个子节点且没有左节点 if (current == root) &#123; root = current.getRightChild(); &#125; else if (isLeftChild) &#123; parent.setLeftChild(current.getRightChild()); &#125; else &#123; parent.setRightChild(current.getRightChild()); &#125; &#125; else &#123; //查找后继节点 Node&lt;T&gt; successor = getSuccessor(current); //情况3.1 如果如果删除节点有两个子节点且后继节点是删除节点的右子节点 if (current == root) &#123; root = successor; &#125; else if (isLeftChild) &#123; parent.setLeftChild(successor); &#125; else &#123; parent.setRightChild(successor); &#125; successor.setLeftChild(current.getLeftChild()); &#125; return current;&#125;private Node&lt;T&gt; getSuccessor(Node&lt;T&gt; delNode) &#123; Node&lt;T&gt; successorParent = delNode; Node&lt;T&gt; successor = delNode; //go to rightChild Node&lt;T&gt; current = delNode.getRightChild(); while (current != null) &#123; //一直往下找左节点 successorParent = successor; successor = current; current = current.getLeftChild(); &#125; //跳出循环，此时successor为最后的一个左节点，也就是被删除节点的后继节点 //如果successor是要删除节点右子节点的左后代 if (successor != delNode.getRightChild()) &#123; //把后继节点的父节点的leftChild字段置为successor的右子节点 successorParent.setLeftChild(successor.getRightChild()); //把successor的rightChild字段置为要删除节点的右子节点。 successor.setRightChild(delNode.getRightChild()); &#125; return successor;&#125; 二叉查找树的遍历前面说过二叉树的遍历主要有四种：前序遍历、后序遍历、层次遍历以及中序遍历。二叉搜索树最常用的遍历方法是中序遍历。 中序遍历中序遍历二叉搜索树会使所有的节点按关键字值升序被访问到。如果希望在二叉树中创建有序的数据序列，这是一种方法。1234567private void inOrder(Node&lt;T&gt; localRoot) &#123; if (null != localRoot) &#123; inOrder(localRoot.getLeftChild()); System.out.println(localRoot.getIndex()); inOrder(localRoot.getRightChild()); &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[做好面试前的准备工作]]></title>
    <url>%2Fconsectetur%2Fmalesuada%2F%E5%81%9A%E5%A5%BD%E9%9D%A2%E8%AF%95%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%2Findex.html</url>
    <content type="text"><![CDATA[做好面试前的准备工作，这个很重要！ 俗话说，磨刀不误砍柴工，做好面试前的准备工作可以帮助大家更好的应对面试官的问题以及面试中的突发情况。 那么面试前我们都有哪些要做的准备工作呢？ 面试之前应对组织进行研究1、公司的背景 公司的性质，老板的背景，创业历史等等。 2、专业资质 对公司在做或即将要做的项目进行分析研究。 3、愿景 公司未来的发展方向、目标或是目前正在实施的计划。 4、文化 公司所倡导的文化、价值观（一般官网会做相关宣传）。 5、其他 其他想要了解的内容，比如乘车路线、公司的薪资福利、未来领导的管理风格等等。 大家可以通过与企业HR的电话沟通中了解，也可以通过企业的官方网站，百度百科，社交朋友圈等渠道进行了解，另外，也可直接找到目标公司的职工进行电话或者面对面的访谈。 对面试过程做预演 1、50/50 原则 说与听的比例最好为1:1，切记滔滔不绝亦或沉默不语。 2、2分钟原则 每次讲话不要超过2分钟，注意与面试官的互动。 注：想要锻炼自己的面谈技巧，可参加学校组织的模拟面试。 事先准备好雇主想听的内容1、针对应聘职位明确优秀雇员核心素质要求 ①、认真分析求职广告中的任职要求； ②、最好找到该岗位的任职者进行访谈（可利用前面提到的脉脉）。 2、整个应聘全过程体现自身具备其核心素质 ①、将自己过往的经历与企业对该岗位的要求进行结合，表明对该岗位的胜任力； ②、认真总结之前工作中的亮点，进行突出。 明确要给雇主留下什么印象最核心的：你非常适合这个职位而且你非常希望得到这个职位。 要点1、千万不要说先前雇主的坏话 2、表现你是这份工作的不二人选 一方面要用实力证明，另一方面要表达对这份工作的信心。 3、不要留露出乞求这份工作的态度 做好心态准备面试就好比是一场考试，在测试每个人的能力，也在测试每个人的心理素质和临场发挥。其中，很重要的一点是：要充满信心。 求职是一个双向选择的过程，企业也迫切需要找到适合的人。（注意：是适合不是最优） 不是每一场面试都会有一个好的结果，这是必然。面试遇挫，不是证明你不好，而是面试的这家公司不适合，仅此而已！ 应对面试，送大家一句话“尽最大的努力，做最坏的打算”。 其他1、项目知识的梳理和准备； 2、相关证件资料的准备（一般公司都会提醒带简历，其他资料要求的较少）； 3、路线的查询，保证不要迟到。]]></content>
      <categories>
        <category>consectetur</category>
        <category>malesuada</category>
      </categories>
      <tags>
        <tag>semper</tag>
        <tag>fermentum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shariding-jdbc分库分表笔记]]></title>
    <url>%2Fshariding-jdbc%2FShariding-jdbc%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AC%94%E8%AE%B0%2Findex.html</url>
    <content type="text"><![CDATA[背景目前yjsj_jianyancgjg已接近1亿，yysy_jianyanbg已达到1000万，且这两张表数据增长十分快速，为了走可持续发展道路，决定对这两张表进行水平拆分。 被淘汰的tidb上周对tidb进行的压力测试，结果表明在持续并发下，tidb不够稳定，会莫名出现查询缓慢导致请求失败的情况，这在业务系统中是不能忍受的，所以排除将数据迁移至tidb的方法，还是使用传统的分库分表方案。 中间件的选择实现分库分表的方式有很多种，市面上也有很多的框架或工具。从切入点来说，整体分为五种: 编码层 在同一个项目中创建多个数据源，采用if else的方式，直接根据条件在代码中路由。Spring中有动态切换数据源的抽象类，具体参见AbstractRoutingDataSource。 如果项目不是很庞大，使用这种方式能够快速的进行分库。但缺点也是显而易见的，需要编写大量的代码，照顾到每个分支。当涉及跨库查询、聚合，需要循环计算结果并合并的场景，工作量巨大。 如果项目裂变，此类代码大多不能共用，大多通过拷贝共享。长此以往，码将不码。 框架层 这种情况适合公司ORM框架统一的情况，但在很多情况下不太现实。主要是修改或增强现有ORM框架的功能，在SQL中增加一些自定义原语或者hint来实现。 通过实现一些拦截器（比如Mybatis的Interceptor接口），增加一些自定义解析来控制数据的流向，效果虽然较好，但会改变一些现有的编程经验。 很多情况要修改框架源码，不推荐。 -驱动层 基于在编码层和框架层切入的各种缺点，真正的数据库中间件起码要从驱动层开始。什么意思呢？其实就是重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。 像TDDL、ShardingJDBC等，都是在此层切入。 包括Mysql Connector/J的Failover协议(具体指“load balancing”、“replication”、“farbic”等），也是直接在驱动上进行修改。 请求流向一般是这样的： 代理层 代理层的数据库中间件，将自己伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。 像MySQL Router、MyCat等，都是在此层切入。 请求流向一般是这样的： 实现层 SQL特殊版本支持，如Mysql cluster本身就支持各种特性，mariadb galera cluster支持对等双主，Greenplum支持分片等。 需要换存储，就不在讨论之列了。 驱动层和代理层对比通过以上层次描述，很明显，我们选择或开发中间件，就集中在驱动层和代理层。在这两层，能够对数据库连接和路由进行更强的控制和更细致的管理。但它们的区别也是明显的。 驱动层的特点 仅支持JAVA，支持丰富的DB 驱动层中间件仅支持Java一种开发语言，但支持所有后端关系型数据库。如果你的开发语言固定，后端数据源类型丰富，推荐使用此方案。 占用较多的数据库连接 驱动层中间件要维护很多数据库连接。比如一个分了10个 库 的表，每个java中的Connection要维护10个数据库连接。如果项目过多，则会出现连接爆炸（我们算一下，如果每个项目6个实例，连接池中minIdle等于5，3个项目的连接总数是 1065*3 = 900 个）。像Postgres这种每个连接对应一个进程的数据库，压力会很大。 运维负担小 所有集群的配置管理都集中在一个地方，运维负担小，DBA即可完成相关操作。 数据聚合在业务实例执行 数据聚合，比如count sum等，是通过多次查询，然后在业务实例的内存中进行聚合。 路由表存在于业务方实例内存中，通过轮询或者被动通知的途径更新路由表即可。 代理层的特点 异构支持，DB支持有限 代理层中间件正好相反。仅支持一种后端关系型数据库，但支持多种开发语言。如果你的系统是异构的，并且都有同样的SLA要求，则推荐使用此方案。 运维负担大 代理层需要维护数据库连接数量有限（MySQL Router那种粘性连接除外）。但作为一个独立的服务，既要考虑单独部署，又要考虑高可用，会增加很多额外节点，更别提用了影子节点的公司了。另外，代理层是请求唯一的入口，稳定性要求极高，一旦有高耗内存的聚合查询把节点搞崩溃了，都是灾难性的事故。 综合考虑后，medical-report使用sharding-jdbc做分库分表,将查报告相关的表单独放入一个数据库实例，对yjsj_jianyancgjg和yysy_jianyanbg做分表处理 信息整理影响业务和项目yjsj_jianyancgjg的影响:查询检验报告详情,调度Job yysy_jianyanbg的影响:文字报告、图片报告、健康档案、Job、报告定制 分表字段的选择现有的查询yjsj_jianyancgjg都是根据机构编号和jianyanid查询，所以可用于分表的字段有jigoubh（机构编号）、jianyanid(医院检验id)。 使用jigoubh分表，是切实可行的，但是数据分布可能不够均匀，比如单单一个金华市中心医院的数据就有1500万 使用jianyanid不一定可行，这个字段存储的是医院的检验id，可能重复，不一定都是数字，可能是字符串。另外用jianyanid分表，对于后面的扩展性不太好。 综合考虑之后，使用customer_id(客户编号)进行分表，由于这两张表都没有customer_id字段，需要用脚本补数据。 sql整理分表分表前，需要将表结构涉及到的所有sql拉出来，充分评估分表后对原有sql的影响。原有sql很大程度上是需要修改的，比如加上分片字段作为条件。 而在业务中，需要考虑是否能够职称sql改写，会不会缺少参数等。如果缺少，还需要对业务代码进行改造。 历史数据处理 step1: 将现有表结构以及数据迁移到单独的库，对于需要迁移的两张表，先放在临时表中。step2: 使用脚本分批次查询临时表中数据，插入到分表后的新表step3: 对于新产生的数据，通过mq的方式，在新系统插入。 step4: 前面三步弄好之后，进行业务迁移，业务迁移完毕之后，关闭DTS数据同步 对数据部分的影响分库分表的改造，涉及表结构以及数据的变更。需要和大数据部门沟通，让他们配合改造。]]></content>
      <categories>
        <category>shariding-jdbc</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字的作用以及原理]]></title>
    <url>%2Fjava%E5%9F%BA%E7%A1%80%2Fvolatile%2Fvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%9C%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86%2Findex.html</url>
    <content type="text"><![CDATA[物理计算机的并发问题CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。内存和硬盘的运算速度和CPU查了几个数量级。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I/O速度和CPU运算速度之间的不匹配问题。 所谓高速缓存也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 但是高速缓存引入了一个新的问题：缓存一致性（Cache Coherence）。在多核CPU系统中，每个CPU都有自己的高速缓存，而它们又公用一块主内存（Main Memory）。当多个CPU的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存不一致。如果真发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？ 解决缓存一致性问题一般来说，有两种方式解决缓存一致性问题 通过在总线加LOCK#锁的方式 通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 缓存一致性协议由于总线加Lock锁的方式效率低下，后来便出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 CPU乱序执行优化除了增加高速缓存外，为了使得处理器内部的运算单元能够尽量被充分利用，处理器可能会对输入代码进行乱序执行(Out-Of-Order Execution)优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行是一致的，但不保证程序中各个语句执行的先后顺序和输入的顺序一致。Java虚拟机的即时编译器也有类似的指令重排序（Instrution Reorder）优化。 Java内存模型Java内存模型和上面处理器、高速缓存、主内存间的交互关系有很高的可比性。Java虚拟机规范视图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽调各种硬件和操作系统的内存访问差异，以实现让Java程序在各个平台下都能达到一致的内存访问效果。 Java内存模型规定了所有的变量(注意这里的变量包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量于方法参数，后者是线程私有的，不会被共享，自然就不会存在竞争问题。)都存储在主内存中。每条线程还有自己的工作内存(Working Memory,可与前面讲得处理器高速缓存类比)，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存完成。 并发中的原子性、可见性、有序性问题原子性所谓原子性或原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程） 在java中，可以大致认为对基本数据类型的访问读写具备原子性 例如：1int a = 10; 但是下面这行代码便不是原子操作了12int a =10;a++; a++ 实际上包含了三个操作: 读取变量a的值； 对a进行加一的操作； 将计算后的值再赋值给变量a 这三个操作无法构成原子性。 如何保证原子性由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write,我们大致可以认为基本数据类型的访问读写是具备原子性的（例 外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。 但是在某些业务场景，需要更大范围的原子性保证。Java内存模型提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更髙展次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块一ynchronized关键字，因此在synchronized块之间的操作也具备原子性。 内存间的交互操作此处扩展下内存间交互操作，Java内存模型中定义了以下8种操作来完成。虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的。 lock(锁定)：作用于主内存中的变量，它把一个变量标识为一个线程独占的状态； unlock(解锁):作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后面的load动作使用； load（载入）：作用于工作内存中的变量，它把read操作从主内存中得到的变量值放入工作内存中的变量副本 use（使用）：作用于工作内存中的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作； assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作； store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中以便随后的write操作使用； write（操作）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中 如果要把一个变量从主内存复制到工作内存。那就要顺序地执行read和load操作，如果要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之间、store与write之间是可插人其他指令的，如对主内存中的变量a、b进行访问时，一种可能出现顺序是read a、read b, load b, load a。 volatile不能保证原子性 volatile不能保证原子性 由于volatile不能保证原子性，在使用volatile时要注意在不符合以下两条规则的运算场景中，我们仍然要通过加锁(使用synchronized或java.util.concurrent中的原子类)来保证原子性。 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束。 可见性可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。Java内存模型是通过在变景修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的。 如何保证可见性synchronized同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的。 让你彻底理解Synchronized finalfinal关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。 volatile被volatile关键字修饰的变量则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。当一个变量被声明为valatile时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存。当其他线程读取该共享变量时，会从主内存重新获取最新值，而不是使用当前线程的工作内存中的值。 下面是一个在双检索单例中，使用volatile关键字的例子。 123456789101112131415161718192021222324252627public class Singleton &#123; /** * 声明单例对象 */ private static volatile Singleton instance; /** * 私有化构造器 */ private Singleton() &#123; &#125; /** * 双重检查加锁 * * @return Singleton */ public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 有序性所谓有序性是指：程序执行的顺序按照代码的先后顺序执行，禁止进行指令重排序。 Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的； 如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”（Within-ThreadAs-IfSerial Semantics）,后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。 如何保证有序性Java语言提供了 volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的。这条规则决定了持有同一个锁的两个同步块只能串行地进入。 除了这两个关键字外，Java 内存模型还具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从 happens-before 原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 如下是 happens-before 的8条原则，摘自 《深入理解Java虚拟机》。 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作； 锁定规则：一个 unLock 操作先行发生于后面对同一个锁的 lock 操作； volatile 变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于他的 finalize() 方法的开始； 在上面双检索单例的代码中，instance = new Singleton(); 这一行代码并不是原子性的，它的底层其实分为三个步骤: 为 Singleton 对象分配内存 memory = allocate(); 初始化对象 设置 instance 指向对象的内存空间 因为步骤 2 和步骤 3 需要依赖步骤 1，而步骤 2 和 步骤 3 并没有依赖关系，所以这两条语句有可能会发生指令重排，也就是或有可能步骤 3 在步骤 2 的之前执行。 在这种情况下，步骤 3 执行了，但是步骤 2 还没有执行，也就是说 instance 实例还没有初始化完毕，正好，在此刻，线程 2 判断 instance 不为 null，所以就直接返回了 instance 实例，但是，这个时候 instance 其实是一个不完全的对象，所以，在使用的时候就会出现问题。 而使用 volatile 关键字，也就是使用了 “对一个 volatile修饰的变量的写，happens-before于任意后续对该变量的读” 这一原则，对应到上面的初始化过程，步骤2 和 3 都是对 instance 的写，所以一定发生于后面对 instance 的读，也就是不会出现返回不完全初始化的 instance 这种可能。 volatile保证有序性的原理是通过添加内存屏障实现的。 # 让你彻底理解volatile]]></content>
      <categories>
        <category>java基础</category>
        <category>volatile</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis zset数据结构使用案例以及原理解析]]></title>
    <url>%2Fredis%2Fredis%20zset%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[前言关于redis，我使用最多的数据结构就是简单的String。对于其他数据结构list、set、hash、zset，乃至于更高级的HyperLogLog、布隆过滤器，基本没有使用过，这次在工作中，恰好遇到需要使用zset的业务场景，特此记录。 zset数据结构介绍zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。 zset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。 zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。 zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。123456789101112131415161718192021222324252627282930313233&gt; zadd books 9.0 "think in java"(integer) 1&gt; zadd books 8.9 "java concurrency"(integer) 1&gt; zadd books 8.6 "java cookbook"(integer) 1&gt; zrange books 0 -1 # 按 score 排序列出，参数区间为排名范围1) "java cookbook"2) "java concurrency"3) "think in java"&gt; zrevrange books 0 -1 # 按 score 逆序列出，参数区间为排名范围1) "think in java"2) "java concurrency"3) "java cookbook"&gt; zcard books # 相当于 count()(integer) 3&gt; zscore books "java concurrency" # 获取指定 value 的 score"8.9000000000000004" # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; zrank books "java concurrency" # 排名(integer) 1&gt; zrangebyscore books 0 8.91 # 根据分值区间遍历 zset1) "java cookbook"2) "java concurrency"&gt; zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) "java cookbook"2) "8.5999999999999996"3) "java concurrency"4) "8.9000000000000004"&gt; zrem books "java concurrency" # 删除 value(integer) 1&gt; zrange books 0 -11) "java cookbook"2) "think in java" 业务场景本次使用到zset的业务是一个挂号底部消息通知的需求。当用户在微脉app上面挂号之后，就诊日期前两天时在底部出现消息提示，提示用户挂号信息，对用户进行引导。 这里只是简单的描述，实际需求比这个复杂很多。完成这个需求的第一步，便是获取用户的预约挂号记录。预约挂号秒的数据量很大，接近1000w，如果每次请求都去查库，势必对数据库造成很大压力。在查询完数据之后放入缓存，可以减缓数据库压力。但是app在推送咨询之后，流量会瞬间暴涨，如果这个时候没有缓存，流量瞬间到了数据库，很有可能造成数据库堵塞，甚至假死。 总之，需要避免app请求这个接口的时候直接去查库，只从redis中取数据，这就需要提前将数据放入缓存。当时考虑的方案有两个，一个是用调度在凌晨将最近3天的预约挂号记录查询出来，放入缓存。一个是当用户产生挂号业务(挂号，取消挂号等)时，发送消息异步更新缓存数据。 第一个方式简单粗暴，改动量小，不过还是要查询数据库，扫表。第二个方式改动量较大，但是不会对数据库造成压力。 综合考虑之后，我们选择了第二种。 redis数据结构的选择不管使用哪一种方案，都需要将用户的挂号信息放入redis，那么使用哪一种数据结构呢？。直接使用简单的String结构，一个挂号信息对应一条redis的key-value，现在我们每天的挂号量有几万，3天大概就是十几万的key，在可以接受的范围内，不过随着业务的发展，key的数量可能会暴涨，不是很好，后面还要优化。 这个时候想到了redis的zset数据结构，一个用户对应一个key，使用就诊日期的时间戳作为score，取的使用使用score取出数据。完全满足这个需求。 附上接受到挂号消息业务之后的伪代码: 12345678910//根据主键查询预约挂号信息MzgyMenZhenYYEntity entity = getRegistrationEntity(registrationId);//根据预约挂号的客户编号生成redis keyString key = GeneratorRedisKeyUtil.createRegistrationKey(entity.getYuyuekhbh());//根据就诊日期计算scorelong score = getScore(entity.getYuyuejzrq());//计算key的过期时间，始终保持key的过期时间在最大就诊日期之后long expireSecond = getExpireSecond(entity.getYuyuejzrq(), key);//放入redisredisClient.zadd(key, (double)score, JSON.toJSONString(convertEntity2DTO(entity)), (int)expireSecond); 取数据的伪代码: 123456789101112131415161718//根据主键查询预约挂号信息String key = GeneratorRedisKeyUtil.createRegistrationKey(customerId);Date now = new Date();//计算startScoreDate start = DateUtil.getSpecialDayStartTime(new Date());//计算endScoreDate end = DateUtil.getSpecialDayEndTime(DateUtil.plusDay(now, 2L));//根据score从redis取数据Set&lt;String&gt; set = redisClient.zrangeByScore(key, start.getTime(), end.getTime());//转换为出参需要的数据结构List&lt;RegistrationInfoDTO&gt; list = new ArrayList&lt;&gt;(set.size());for (String json : set) &#123; list.add(JSON.parseObject(json, RegistrationInfoDTO.class));&#125;return list; zset底层原理以下内容节选至老钱的《Redis深度历险:核心原理与应用》 侵删 zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。 因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。 我们需要这个链表按照 score 值进行排序。这意味着当有新元素需要插入时，要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？ 想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级 —— 部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。 跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。 想想你老家在世界地图中的位置：亚洲–&gt;中国-&gt;安徽省-&gt;安庆市-&gt;枞阳县-&gt;汤沟镇-&gt;田间村-&gt;xxxx号，也是这样一个类似的结构。 「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于 L0、L1 和 L2 层，可以快速在不同层次之间进行「跳跃」。 定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问，那新插入的元素如何才有机会「身兼数职」呢？ 跳跃列表采取一个随机策略来决定新元素可以兼职到第几层。 首先 L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。 这还挺公平的，能不能进入中央不是靠拼爹，而是看运气。 关于跳跃列表的内部结构实现，请阅读第 36 节凌波微步 —— 探索「跳跃列表」内部结构]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO模型]]></title>
    <url>%2Funcategorized%2FJava-IO%E6%A8%A1%E5%9E%8B%2Findex.html</url>
    <content type="text"><![CDATA[Linux系统的五种IO模式Java 的 IO 模型本质上还是利用操作系统提供的接口来实现,所以最好先了解Linux底层模型。推荐阅读Linux IO模式及 select、poll、epoll详解 Java IO模型的演变BIO在JDK1.4之前，基于Java的所有Socket通信都采用同步阻塞模式(BIO)，这种一请求一应答的通信模型简化了上层的应用开发，但是在性能和可靠性方面却存在着巨大的瓶颈。当并发量增大，响应时间延迟增大之后，采用Java BIO开发的服务端只有通过硬件的不断扩容来满足高并发和低延迟，它极大的增加了企业的成本，随着集群规模的不断膨胀，系统的可维护性也面临巨大的挑战。 代码类似这样: 12345678910111213141516171819202122232425262728293031323334353637public class BlokingIoServer implements Runnable&#123; @Override public void run() &#123; try &#123; //将服务绑定到指定端口 ServerSocket ss = new ServerSocket(8888); while (!Thread.interrupted())&#123; //对 accept()方法的调 用将被阻塞，直到一个连接建立 final Socket clientSocket = ss.accept(); //为每个请求创建一个线程来处理 new Thread(new Handler(clientSocket)).start(); &#125; // or, single-threaded, or a thread pool &#125; catch (IOException ex) &#123; /* ... */ &#125; &#125; static class Handler implements Runnable &#123; final Socket socket; Handler(Socket s)&#123; socket = s; &#125; @Override public void run() &#123; try &#123; byte[] input = new byte[1024]; socket.getInputStream().read(input); byte[] output = process(input); socket.getOutputStream().write(output); &#125; catch (IOException ex) &#123; /* ... */ &#125; &#125; private byte[] process(byte[] cmd)&#123; //do something return null; &#125; &#125;&#125; Web服务，大多数有着类似的流程:Read request (从底层IO读取网络字节请求)Decode request (把读取的网络字节请求进行解码,封装成为业务请求对象)Process service (对解码封装后的业务请求对象进行业务处理)Encode reply (将业务逻辑处理完后的响应进行编码为底层IO可传输的字节响应)Send reply (利用底层IO发送已编码的字节响应) 不同之处在于，每一个步骤底层使用的技术和手段不同，比如:XML解析,文件传输,Web页面生成,计算服务….. 经典(传统)的网络服务设计如上图所示，对每个请求都会产生一个新的线程来进行处理，这种设计的缺点是，线程的创建本身是系统资源的一个开销，如果并发请求达到一定数量，响应将会变慢，甚至有可能因为系统资源不足而造成系统崩溃。 伪异步I/O编程为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化，后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M:线程池最大线程数N的比例关系，其中M可以远远大于N,通过线程池可以灵活的调配线程资源， 设置线程的最大值， 防止由于海量并发接入导致线程耗尽。 当有新的客户端接入的吋候，将客户端的Socket封装成一个Task （该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK的线程池维护一个消息队列和N个活跃线程对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class TimeServer &#123; public static void main(String[] args) throws IOException &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; //采用默汄值 &#125; &#125; ServerSocket server = null; try &#123; server = new ServerSocket(port); System.out.println("The time server is start in port :" + port); Socket socket = null; TimeServerHandlerExecutePool singleExecutor = new TimeServerHandlerExecutePool(50, 10000); while (true) &#123; socket = server.accept(); singleExecutor.execute(new TimeServerHandler(socket)); &#125; &#125; finally &#123; if (server != null) &#123; System.out.println("The time server close11"); server.close(); server = null; &#125; &#125; &#125;&#125;public class TimeServerHandlerExecutePool &#123; private ExecutorService executor; public TimeServerHandlerExecutePool(int maxPoolSize, int queueSize) &#123; executor = new ThreadPoolExecutor(Runtime.getRuntime().availableProcessors(), maxPoolSize, 120L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(queueSize)); &#125; public void execute(java.lang.Runnable task) &#123; executor.execute(task); &#125;&#125;public class TimeServerHandler implements Runnable &#123; private Socket socket; public TimeServerHandler(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; BufferedReader in = null; PrintWriter out = null; try &#123; in = new BufferedReader(new InputStreamReader(this.socket.getInputStream())); out = new PrintWriter(this.socket.getOutputStream(), true); String currentTime = null; String body = null; while (true) &#123; body = in.readLine(); if (body == null) &#123; break; &#125; System.out.println("The time server receive order : " + body); currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()) .toString() : "BAD ORDER"; System.out.println(currentTime); &#125; &#125; catch (Exception e) &#123; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException el) &#123; el.printStackTrace(); &#125; if (out != null) &#123; out.close(); out = null; &#125; if (this.socket != null) &#123; try &#123; this.socket.close(); &#125; catch (IOException el) &#123; el.printStackTrace(); &#125; this.socket = null; &#125; &#125; &#125; &#125;&#125; 伪异步IO解决了线程的频繁创建销毁问题，但是如果通信对方返回应答时间过长，会引起级联故障，比如下面的场景: 服务端处理缓慢，返回应答消息耗费60s，平时只需要10ms。 采用伪异步IO的线程正在读取故障服务节点的响应，由于读取输入流是阻塞的，因此，它将会被同步阻塞60s。 假如所有的可用线程都被故障服务器阻塞，那后续所有的IO消息都将在队列中排队。 由于线程池采用阻塞队列实现，将队列积满之后，后续入队列的操作将被阻塞。 由于前段只有一个Accptor线程接口客户端接入，它被阻塞在线程池的同步阻塞队列之后，新的客户端请求消息将被拒绝，客户端会发生大量的连接超时。 由于几乎所有的连接都超时，调用者会认为系统崩溃，无法接受新的请求消息。 NIONIO，有人解释为new I/O,有人解释为Non-block I/O(我更倾向后者)。 正是由于Java传统BIO的拙劣表现，才使得Java支持非阻塞I/O的呼声日渐高涨，最终，JDK1.4版本提供了新的NIO类库，Java终于也可以支持非阻塞I/O 了。NIO主要的类和接口如下: 进行异步I/O操作的缓冲区ByteBuffer等; 进行异步I/O操作的管道Pipe； 进行各种I/O操作（异步或者同步）的Channel,包括ServerSocketChannel和 SocketChannel： 多种字符集的编码能力和解码能力； 实现非阻塞I/O操作的多路复用器selector： 基千流行的Perl实现的正则表达式类库； 文件通道FileChannelo。 新的NIO类库的提供，极大地促进了基于Java的异步非阻塞编程的发展和应用，但是，它依然有不完善的地方，特别是对文件系统的处理能力仍显不足，主要问题如下。 没有统一的文件属性（例如读写权限）； API能力比较弱，例如目录的级联创建和递归遍历，往往需要自己实现： 底层存储系统的一些高级API无法使用： 所有的文件操作都是同步阻塞调用，不支持异步文件读写操作。 2011年7月28日，JDKI.7正式发布。她将原来的NIO类库进行了升级，被称为NIO2.0。它主要提供了如下三个方面的改进。 能够提供能够批量获取文件属性的API，这些API具有平台无关性，不与特定的文件系统相耦合，另外它还提供了标准文件系统的SPI,供各个服务提供商扩展实现； 提供AIO功能，支持基于文件的异步I/O操作和针对网络套接字的异步操作； 完成JSR-5I定义的通道功能，包括对配置和多播数据报的支持等； NIO类库概念和功能介绍缓冲区BufferBuffer是一个对象，它包含一些要写入或者要读出的数据。在NIO库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，写入到缓冲区中。任何吋候访问NIO中的数据，都是通过缓冲区进行操作。 缓冲区实质上是一个数组。通常它是一个字节数组(ByteBuffer),也可以使用其他种类的数组。但是一个缓冲区不仅仅是一个数组，缓冲区提供了对数据的结构化访问以及维护读写位置(limit)等信息。 最常用的缓冲区是ByteBuffer, 一个ByteBuffer提供了一组功能用于操作byte数组。除了 ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型(除了 Boolean类型)都对应有一种缓冲区，具体如下。 ByteBuffer：字节缓冲区 CharBuffer：字符缓冲区 ShortBuffer：短整型缓冲K IntBuffer：整形缓冲区 LongBuffer：长整形缓冲区 FloatBuffer：浮点型缓冲区 DoubleBuffer： 双精度浮点型缓冲区 每—个Buffer类都是Buffer接口的一个T实例。除了 ByteBuffer,每一个Buffe类都有完全一样的操作，只是它们所处理的数据类型不一样。因为大多数标准I/O操作都使用ByteBuffer,所以它除了具有一般缓冲区的操作之外还提供一些特有的操作，方便网络读写。 管道channelChannel是一个通道，可以通过它读取和写入数据，它就像自来水管一样，网络数据通过Channel读取和写入。通道与流的不同之处在于通道是双向的，流只是在一个方向上移动（一个流必须是InputStream或者OutputStream的子类），而且通道可以用于读、写或者同时用于读写。 Channel的类继承图如下。 因为Channel是全双工的，所以它可以比流更好地映射底层操作系统的API。特别是在UNIX网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作。 多路复用器Selector多路复用器提供选择已经就绪的任务的能力。 简单来讲， Selector会不断地轮询注册在其上的Channel,如果某个Channel上面有新的TCP 连接接入、 读和写事件， 这个Channel就处于就绪状态， 会被Selector轮询出来， 然后通过SelectionKey可以获取就绪Channel的集合， 进行后续的I/O操作。 使用NIO实现服务端 123456789101112131415161718192021public class TimeServerNio &#123; public static void main(String[] args) &#123; //设置监听端口 int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; //采用默认值 &#125; &#125; //创建了一个被称为MultiplexerTimeServer的多路复用类， 它是个一个独立 //的线程， 负责轮洵多路复用器Selctor,可以处理多个客户端的并发接入 MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port); new Thread(timeServer, "NIO-MultiplexerTirneServer-001H").start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138public class MultiplexerTimeServer implements Runnable &#123; private Selector selector; private ServerSocketChannel servChannel; private volatile boolean stop; /** * 在构造方法中进行资源初始化， 创建多路复用器Selector、 * ServerSocketChannel,对 Channel 和 TCP 参数进行配置 * * @param port */ public MultiplexerTimeServer(int port) &#123; try &#123; selector = Selector.open(); servChannel = ServerSocketChannel.open(); //设置为异步非阻塞模式 servChannel.configureBlocking(false); servChannel.socket().bind(new InetSocketAddress(port), 1024); //注册selector servChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println("The time server is start in port : " + port); &#125; catch (IOException e) &#123; //资源初始化失败，退出系统 e.printStackTrace(); System.exit(1); &#125; &#125; public void stop() &#123; this.stop = true; &#125; @Override public void run() &#123; while (!stop) &#123; try &#123; //循环遍历selector,它的休眠时间为1s selector.select(1000); //返回就绪状态的Channel的SelectionKey集合 Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; //通过对就绪状态的Channel集合进行迭代， 可以进行网络的异步读写操作 while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) &#123; key.channel().close(); &#125; &#125; &#125; &#125; &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125; // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null) &#123; try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; // 处理新接入的请求消息 if (key.isAcceptable()) &#123; // Accept the new connection ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); // Add the new connection to the selector sc.register(selector, SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; // Read the data SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) &#123; readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, "UTF-8"); System.out.println("The time server receive order : " + body); String currentTime = "QUERY TIME ORDER" .equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : "BAD ORDER"; doWrite(sc, currentTime); &#125; else if (readBytes &lt; 0) &#123; // 对端链路关闭 key.cancel(); sc.close(); &#125; else &#123; ; // 读到0字节，忽略 &#125; &#125; &#125; &#125; /** * 将应答消息异步发送给客户端 * * @param channel channel * @param response response * @throws IOException exception */ private void doWrite(SocketChannel channel, String response) throws IOException &#123; if (response != null &amp;&amp; response.trim().length() &gt; 0) &#123; //将字符串编码成字节数组， 根据字节数组的容量创建ByteBuff byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); //将字节数据复制到缓冲区 writeBuffer.put(bytes); writeBuffer.flip(); //将缓冲区中的字节数组发送出去 channel.write(writeBuffer); &#125; &#125;&#125; 使用NIO实现客户端 12345678910111213141516public class TimeClientNio &#123; public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new Thread(new TimeClientHandle("127.0.0.1", port), "TimeClient-001") .start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class TimeClientHandle implements Runnable&#123; private String host; private int port; private Selector selector; private SocketChannel socketChannel; private volatile boolean stop; /** * implements Runnable * * @param host host * @param port port */ public TimeClientHandle(String host, int port) &#123; this.host = host == null ? "127.0.0.1" : host; this.port = port; try &#123; selector = Selector.open(); socketChannel = SocketChannel.open(); //设置为异步非阻塞模式 socketChannel.configureBlocking(false); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; @Override public void run() &#123; try &#123; //发送连接请求 doConnect(); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; while (!stop) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) key.channel().close(); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null)&#123; try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; // 判断是否连接成功 SocketChannel sc = (SocketChannel) key.channel(); //如果返回值为true,说明客户端连接成功 if (key.isConnectable()) &#123; if (sc.finishConnect()) &#123; sc.register(selector, SelectionKey.OP_READ); doWrite(sc); &#125; else &#123; System.exit(1);// 连接失败，进程退出 &#125; &#125; if (key.isReadable()) &#123; //预分配1M的接收缓冲K用于读取应答消息， 调川Socketchannel的read()方法进行异步读取操作 ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) &#123; readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, "UTF-8"); System.out.println("Now is : " + body); this.stop = true; &#125; else if (readBytes &lt; 0) &#123; // 对端链路关闭 key.cancel(); sc.close(); &#125; else ; // 读到0字节，忽略 &#125; &#125; &#125; private void doConnect() throws IOException &#123; // 如果直接连接成功，则注册到多路复用器上，发送请求消息，读应答 if (socketChannel.connect(new InetSocketAddress(host, port))) &#123; socketChannel.register(selector, SelectionKey.OP_READ); doWrite(socketChannel); &#125; else &#123; //如果没有直接连接成功， 则说明服务端没有返回TCP握手应答消息， 但这并不代表连接失败， 我们需要将SocketChannel //注册到多路复用器Selector上， 注册SelectionKey.OP CONNECT»当服务端返回TCP //syn-ack消息后， Selector就能够轮询到这个SocketChannel处于连接就绪状态 socketChannel.register(selector, SelectionKey.OP_CONNECT); &#125; &#125; private void doWrite(SocketChannel sc) throws IOException &#123; byte[] req = "QUERY TIME ORDER".getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); sc.write(writeBuffer); //hasRemaining()方法对发送结果进行判断， 是否全部发送完成 if (!writeBuffer.hasRemaining()) &#123; System.out.println("Send order 2 server succeed."); &#125; &#125;&#125; NIO编程难度确实比同步阻塞BIO大很多， 上面的NIO 例子并没有考虑“ 半包读” 和“ 半包写” ， 如果加上这些， 代码将会更加复杂。 NIO优点总结 客户端发起的连接操作是异步的， 可以通过在多路复用器注册OP_CONNECT等待后续结果， 不需要像之前的客户端那样被同步阻塞。 Socketchannel的读写操作都是异步的， 如果没有可读写的数据它不会同步等待，直接返回， 这样I/O通信线程就可以处理其他的链路， 不需要同步等待这个链路可用。 线程模型的优化： 由于JDK的Selector在Linux等主流操作系统上通过epoll实现， 它没有连接句柄数的限制(只受限于操作系统的最大句柄数或者对单个进程的句柄限制)， 这意味着一个Selector线程可以同时处理成千上万个客户端连接， 而且性能不会随着客户端的增加而线性下降， 因此， 它非常适合做高性能、 高负载的网络服务器。 AIONIO2.0引入了新的异步通道概念，并提供了异步文件通道和异步套接字通道的实现。异步通道提供两种方式获取操作结果. 通过java.util.concurrent.Future类來表示异步操作的结果； 在执行异步操作的时候传入一个java.nio.channels。 CompletionHandler接口的实现类作为操作完成的回调。 NIO2.0的异步套接字通道是真正的异步非阻塞I/O,它对应UNIX网络编程中的事件驱动I/O (AIO),它不需要通过多路复用器(Selector)对注册的通道进行轮询操作即可实现异步读写， 从而简化了 NIO的编程模型。 aio服务端代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public class TimeServerAio &#123; public static void main(String[] args) throws IOException &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; //创建异步的时间服务器处理类 AsyncTimeServerHandler timeServer = new AsyncTimeServerHandler(port); new Thread(timeServer, "AIO-AsyncTimeServerHandler-001").start(); &#125;&#125;public class AsyncTimeServerHandler implements Runnable&#123; private int port; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; /** * 创建一个异步的服务端通道AsynchronousServerSocketChannel， 然后调H］它的 * bind h'法绑定监听端口， 如果端口合法且没被占用， 绑定成功， 打印启动成功提示到控 * 制台 * * @param port port */ public AsyncTimeServerHandler(int port) &#123; this.port = port; try &#123; asynchronousServerSocketChannel = AsynchronousServerSocketChannel .open(); asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); System.out.println("The time server is start in port : " + port); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; //初始化CountDownLatch对象， 它的作用是在完成一组正在执行的操作之前， 允许当前的线程一直阻塞.在本例程中， 我们让线程在此阻塞, //防止服务端执行完成退出。 在实际项目应用中， 不需要启动独立的线程來处理 //AsynchronousServerSocketChannel latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void doAccept() &#123; //接收客户端的选接 asynchronousServerSocketChannel.accept(this, new AcceptCompletionHandler()); &#125;&#125;public class AcceptCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel, AsyncTimeServerHandler&gt; &#123; @Override public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment) &#123; attachment.asynchronousServerSocketChannel.accept(attachment, this); ByteBuffer buffer = ByteBuffer.allocate(1024); result.read(buffer, buffer, new ReadCompletionHandler(result)); &#125; @Override public void failed(Throwable exc, AsyncTimeServerHandler attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125;&#125;public class ReadCompletionHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompletionHandler(AsynchronousSocketChannel channel) &#123; if (this.channel == null) &#123; this.channel = channel; &#125; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); byte[] body = new byte[attachment.remaining()]; attachment.get(body); try &#123; String req = new String(body, "UTF-8"); System.out.println("The time server receive order : " + req); String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(req) ? new java.util.Date( System.currentTimeMillis()).toString() : "BAD ORDER"; doWrite(currentTime); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; private void doWrite(String currentTime) &#123; if (currentTime != null &amp;&amp; currentTime.trim().length() &gt; 0) &#123; byte[] bytes = (currentTime).getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; // 如果没有发送完成，继续发送 if (buffer.hasRemaining()) &#123; channel.write(buffer, buffer, this); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; this.channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; aio客户端代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public class TimeClientAio &#123; public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new Thread(new AsyncTimeClientHandler("127.0.0.1", port), "AIO-AsyncTimeClientHandler-001").start(); &#125;&#125;public class AsyncTimeClientHandler implements CompletionHandler&lt;Void, AsyncTimeClientHandler&gt;, Runnable&#123; private AsynchronousSocketChannel client; private String host; private int port; private CountDownLatch latch; public AsyncTimeClientHandler(String host, int port) &#123; this.host = host; this.port = port; try &#123; client = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); client.connect(new InetSocketAddress(host, port), this, this); try &#123; latch.await(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncTimeClientHandler attachment) &#123; byte[] req = "QUERY TIME ORDER".getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); client.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; if (buffer.hasRemaining()) &#123; client.write(buffer, buffer, this); &#125; else &#123; ByteBuffer readBuffer = ByteBuffer.allocate(1024); client.read( readBuffer, readBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; buffer.flip(); byte[] bytes = new byte[buffer .remaining()]; buffer.get(bytes); String body; try &#123; body = new String(bytes, "UTF-8"); System.out.println("Now is : " + body); latch.countDown(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncTimeClientHandler attachment) &#123; exc.printStackTrace(); try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 异步Socket Channel是被动执行对象， 我们不需要像 NIO编程那样创建一个独立的 I/O线程来处理读写操作。 对于AsynchronousServerSocketChannel和AsynchronousSocketChannel,它们都由JDK底层的线程池负责回调并驱动读写操作 #4中IO模型功能和特性对比]]></content>
  </entry>
  <entry>
    <title><![CDATA[==，equals，hashCode的区别和联系]]></title>
    <url>%2Fjava%E5%9F%BA%E7%A1%80%2Fequals%2F%3D%3D%EF%BC%8Cequals%EF%BC%8ChashCode%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB%2Findex.html</url>
    <content type="text"><![CDATA[== 和equals== 比较的是对象在内存的地址。equals()定义在Object中。123public boolean equals(Object obj) &#123; return (this == obj);&#125; 这意味着所有对象都有equals()方法,并且默认情况下equals()方法和==一样比较的是对象在内存的地址值。一般引用数据类型之间的比较，需要重写equals，让其比较对象的字段值。 hashCode()方法的作用1public native int hashCode(); hashCode()方法注释翻译: 返回该对象的哈希码值。支持此方法是为了提高哈希表（例如 java.util.Hashtable 提供的哈希表）的性能。 hashCode的的常规协定是: 在 Java 应用程序执行期间，在对同一对象多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是将对象进行 equals 比较时所用的信息没有被修改。从某一应用程序的一次执行到同一应用程序的另一次执行，该整数无需保持一致。 如果根据equals(Object)方法两个对象相等，那么对两个对象调用hashCode方法必须产生相同的整数结果。 如果两个对象根据equals(java.lang.Object)方法是不相等的，那么调用这两个对象上的hashCode方法必须产生不同的整数结果。但是，程序员应该意识到，为不相等的对象生成不同的整数结果可能会提高哈希表的性能。 实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧。） 注意这一句话： “支持此方法是为了提高哈希表（例如 java.util.Hashtable 提供的哈希表）的性能。” 也就是说，虽然每个Java类都包含hashCode() 函数。但是，仅仅当创建并某个“类的散列表”时(比如HashMap)，该类的hashCode() 才有用(作用是：确定该类的每一个对象在散列表中的位置)；其它情况下(例如，创建类的单个对象，或者创建类的对象数组等等)，类的hashCode() 没有作用。 上面的散列表，指的是：Java集合中底层是散列表的类，如HashMap，Hashtable，HashSet。 关于散列表更过详细的介绍，可以参考哈希表、Java中HashMap equals()和hashCode()的区别和联系面试的时候，经常会被问到，为什么重写equals方法的时候需要重写hashCode()？我们来看一个只重写equals的demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import java.util.HashSet;import java.util.Objects;import org.apache.commons.lang3.builder.ToStringBuilder;import org.apache.commons.lang3.builder.ToStringStyle;/** * * @author keji * @version $Id: HashCodeAndEquals.java, v 0.1 2018/12/12 6:40 PM keji Exp $ */public class HashCodeAndEquals &#123; public static void main(String[] args) &#123; User p1 = new User(100,"eee"); User p2 = new User(100,"eee"); User p3 = new User(200,"aaa"); HashSet&lt;User&gt; hashSet = new HashSet&lt;&gt;(); hashSet.add(p1); hashSet.add(p2); hashSet.add(p3); System.out.printf("p1.equals(p2) : %s; p1(%d) p2(%d)\n", p1.equals(p2), p1.hashCode(), p2.hashCode()); System.out.printf("set:%s\n", hashSet); &#125; private static class User&#123; private int age; private String name; public User(int age, String name) &#123; this.age = age; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; User user = (User)o; return age == user.age &amp;&amp; Objects.equals(name, user.name); &#125; @Override public String toString() &#123; return ToStringBuilder.reflectionToString(this, ToStringStyle.SHORT_PREFIX_STYLE); &#125; &#125;&#125;输出结果:p1.equals(p2) : true; p1(189568618) p2(793589513)set:[HashCodeAndEquals.User[age=100,name=eee], HashCodeAndEquals.User[age=100,name=eee], HashCodeAndEquals.User[age=200,name=aaa]] 可以看到，在只重写equals，没有重写hashcode的情况下。equals相等，但是hashcode不相等，导致HashSet中仍然有重复元素：p1和p2。 当在原来的基础上，重写HashCode，再次执行main()12345678@Overridepublic int hashCode() &#123; return Objects.hash(age, name);&#125;输出结果如下：p1.equals(p2) : true; p1(104354) p2(104354)set:[HashCodeAndEquals.User[age=100,name=eee], HashCodeAndEquals.User[age=200,name=aaa]] 所有，当我们在HashMap,HashTable,HashSet等这些底层使用散列表的数据结构时，如果我们只重写equals()而不重写hashCode()，并不能很好的利用他们的特性。 但是，当我们明确对象不会再HashMap,HashTable,HashSet等这些数据结构中使用时，我们不重写hashCode()写是可以的。1234567891011121314151617181920User p1 = new User(100,"eee");User p2 = new User(100,"eee");User p3 = new User(200,"aaa");ArrayList&lt;User&gt; list1 = new ArrayList&lt;&gt;();list1.add(p1);list1.add(p2);list1.add(p3);ArrayList&lt;User&gt; list2 = new ArrayList&lt;&gt;();list2.add(p1);list2.add(p2);list2.add(p3);System.out.printf("p1.equals(p2) : %s; p1(%d) p2(%d)\n", p1.equals(p2), p1.hashCode(), p2.hashCode());System.out.printf("p1.equals(p3) : %s; p1(%d) p3(%d)\n", p1.equals(p3), p1.hashCode(), p3.hashCode());System.out.printf("list1.equals(list2) :%s\n",list1.equals(list2));输出结果：p1.equals(p2) : true; p1(104354) p2(104354)p1.equals(p3) : false; p1(104354) p3(103482)list1.equals(list2) :true 关于HashCode和equals的区别和联系，网络上有这样一个结论:当equals相等时,HashCode一定相等。当HashCode相等时，equals不一定相等。 这个结论不能说它是错的，但是它有一个前提是对equals和hashCode()进行了重写。 重写equals的同时重写hashCode(反之亦然)，这是一种规范。虽然前面说过如果对象不存储在HashMap、HashSet、HashTab等这些对象中时，hashCode是无用的，但是谁敢在设计这个对象的时候保证该对象以后不会再这些数据结构中使用？ 综上所述，重写equals的时候，要重写hashCode方法。]]></content>
      <categories>
        <category>java基础</category>
        <category>equals</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java集合之ArrayList 源码解析]]></title>
    <url>%2Fjava%E5%9F%BA%E7%A1%80%2F%E9%9B%86%E5%90%88%2FArrayList%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2Findex.html</url>
    <content type="text"><![CDATA[ArrayList是Java最常用的几种数据结构之一， 同时也是面试热点。了解其内部实现原理是非常必要的。 创建ArrayList123ArrayList&lt;Object&gt; list1 = new ArrayList&lt;&gt;();ArrayList&lt;Object&gt; list2 = new ArrayList&lt;&gt;(16);ArrayList&lt;Object&gt; list3 = new ArrayList&lt;&gt;(list2); ArrayList为我们提供了三个构造方法。我们创建ArrayList对象除了使用空参构造，还可以传递一个int数值，指定初始容量或者传递一个集合。 空参构造ArrayList()123456/** * Constructs an empty list with an initial capacity of ten. */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 空参构造非常简单，它会为我们创建一个空的集合。elementData成员变量是用来存放数据的对象,是一个Object[]，DEFAULTCAPACITY_EMPTY_ELEMENTDATA则是一个空的数组。 123456/** * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when * first element is added. */private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; 注意DEFAULTCAPACITY_EMPTY_ELEMENTDATA类型为static final，表明其在内存中只有一份且禁止修改。 1234567/** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */transient Object[] elementData; // non-private to simplify nested class access 注意elementData使用transient修饰。表明在采用Java默认的序列化机制的时候，被该关键字修饰的属性不会被序列化。而ArrayList类实现了java.io.Serializable接口，即采用了Java默认的序列化机制。但是elementData在网络传输的时候不序列化肯定是不行的，翻看源码会发现ArrayList自己实现了序列化和反序列化的方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Save the state of the &lt;tt&gt;ArrayList&lt;/tt&gt; instance to a stream (that * is, serialize it). * * @serialData The length of the array backing the &lt;tt&gt;ArrayList&lt;/tt&gt; * instance is emitted (int), followed by all of its elements * (each an &lt;tt&gt;Object&lt;/tt&gt;) in the proper order. */private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;/** * Reconstitute the &lt;tt&gt;ArrayList&lt;/tt&gt; instance from a stream (that is, * deserialize it). */private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125; 空参构造底层为我们创建的是一个空的数组，初始容量是0，这肯定没法存东西的，必然会使用的时候进行扩容。我们来看下add()方法1234567891011/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 首先，调用了ensureCapacityInternal()方法，入参传递了size+1，size+1表示elementData所需要的最小长度。这里的size变量，是用来记录ArrayList包含元素的多少的，初始值为0，我们调用ArrayList的size()方法，返回的就是该字段。123456/** * The size of the ArrayList (the number of elements it contains). * * @serial */private int size; 看下ensureCapacityInternal()的源码:123private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125; 简单点说，该方法做了一件事情，判断当前数组能不能方法即将被添加的元素，如果不能，扩容。 首先调用了calculateCapacity()计算容量，代码如下:123456private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125; 如果集合还没有被初始化，则初始化容量为10。如果已经初始化过了，直接返回。1234/** * Default initial capacity. */private static final int DEFAULT_CAPACITY = 10; 调用完calculateCapacity()后，调用ensureExplicitCapacity(),这个方法做了两件事情：1.将modCount自增2.如果容量不够，扩容。12345678private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //扩容 grow(minCapacity);&#125; 我们先将modCount属性放到一边，看下扩容的方法grow()。 1234567891011121314151617/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */ private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; 可以看到扩容后的容量为原容量的1.5倍+1。另外网上很多文章说ArrayList是无限扩容的，其实不是，它是有限度的。上面的代码有一个判断:12if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); 如果扩容后的容量比数组最大容量大，调用hugeCapacity()方法，并将扩容前所需要的最小容量传递的进去。1234567private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; hugeCapacity方法只在扩容时可能被调用，它的逻辑很简单，先做了个简单的判断，之后执行了一个三元表达式，如果扩容前所需最小容量大于数组最大长度，返回Integer的最大值，否则返回MAX_ARRAY_SIZE,MAX_ARRAY_SIZE的Integer的最大值-8。1234567/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; int的最大值为2的31次方-1，所以说ArrayList的最大容量为2的31次方-1。12345/** * A constant holding the maximum value an &#123;@code int&#125; can * have, 2&lt;sup&gt;31&lt;/sup&gt;-1. */@Native public static final int MAX_VALUE = 0x7fffffff; 回过头来在看我们调用空参构造创建一个ArrayList，并且第一次调用add()方法时发生了什么？扩容，是的，它会将默认的空数组扩容为一个长度为10的数组。 初始化指定集合大小ArrayList(int initialCapacity)《阿里巴巴Java开发手册》里面建议初始化集合时尽量显示的指定集合大小。为什么？读了上面的源码之后，应该可以知道答案了。1.节约内存，实际编码中，很多时候我们都可以知道ArrayList里面会放什么元素以及放多少元素。恰当的设置容器大小可以节约内存。2.避免扩容产生的性能损耗。比如我知道这个集合要放11个元素，那么我可以将集合的大小初始化为11，这样可以避免在添加第11个元素的时候，ArrayList扩容。 ArrayList的扩容底层调用了native方法System.arraycopy()简单点说就是将原来的数组中的元素拷贝到一个新的更大的数组中去。 看下指定初始容量构造的源码:1234567891011121314151617/** * Constructs an empty list with the specified initial capacity. * * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; 逻辑非常简单，如果初始容量&gt;0，则创建一个该大小的数组。如果容量为0，则创建一个空数组。如果容量&lt;0，抛出异常。 初始化传递集合ArrayList(Collection&lt;? extends E&gt; c)12345678910111213141516171819/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 逻辑并不复杂，直接将集合转换为Object数组，赋值给了elementData属性。后面还做了一些保障性操作。 添加元素再探add(E e)方法前面已经看过一点add()方法的源码，知道它首先会确认容量是否够用，如果不够，则进行扩容。注意ArrayList的扩容时机和HashMap有区别，ArrayList只有底层数组已满，不能放下即将存入的对象才会扩容，HashMap的扩容和加载因子有关系，默认情况下，不是容器满了才扩容。123456789101112/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 在确保容量够用之后，直接要添加的元素赋值给elementData数组的下一个空间。 添加到指定位置add(int index, E element)123456789101112131415161718/** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; //检查index是否在已有的数组中 if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException("Index:"+index+",Size:"+size); ensureCapacity(size + 1);//确保对象数组elementData有足够的容量，可以将新加入的元素e加进去 System.arraycopy(elementData, index, elementData, index+1, size-index);//将index及其后边的所有的元素整块后移，空出index位置 elementData[index] = element;//插入元素 size++;//已有数组元素个数+1&#125; 使用这个方法，务必注意index的值需要在已经元素的下标之间。 添加所有addAll(Collection&lt;? extends E&gt; c)123456789101112131415161718192021/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the * specified collection's Iterator. The behavior of this operation is * undefined if the specified collection is modified while the operation * is in progress. (This implies that the behavior of this call is * undefined if the specified collection is this list, and this * list is nonempty.) * * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray();//将c集合转化为对象数组a int numNew = a.length;//获取a对象数组的容量 ensureCapacity(size + numNew);//确保对象数组elementData有足够的容量，可以将新加入的a对象数组加进去 System.arraycopy(a, 0, elementData, size, numNew);//将对象数组a拷贝到elementData中去 size += numNew;//重新设置elementData中已加入的元素的个数 return numNew != 0;//若加入的是空集合则返回false&#125; ##添加所有到指定位置addAll(int index, Collection&lt;? extends E&gt; c)12345678910111213141516public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125; 删除元素删除指定索引元素 E remove(int index)。123456789101112131415161718192021222324252627/** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). * * @param index the index of the element to be removed * @return the element that was removed from the list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; //索引边界检查 rangeCheck(index); //计数器自增 modCount++; //取得被删除元素 E oldValue = elementData(index); //计算要移动的索引值 int numMoved = size - index - 1; if (numMoved &gt; 0) //如果删除的不是最后一个元素，进行数组拷贝 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将最后一个元素置为null，下次gc回收 elementData[--size] = null; // clear to let GC do its work //返回被删除的值 return oldValue;&#125; 删除指定值的元素 remove(Object o)1234567891011121314151617181920212223242526272829/** * Removes the first occurrence of the specified element from this list, * if it is present. If the list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists). Returns &lt;tt&gt;true&lt;/tt&gt; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &lt;tt&gt;true&lt;/tt&gt; if this list contained the specified element */public boolean remove(Object o) &#123; if (o == null) &#123;//移除对象数组elementData中的第一个null for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123;//移除对象数组elementData中的第一个o for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125; 12345678910/* * 删除单个位置的元素，是ArrayList的私有方法 */private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0)//删除的不是最后一个元素 System.arraycopy(elementData, index + 1, elementData, index,numMoved);//删除的元素到最后的元素整块前移 elementData[--size] = null; //将最后一个元素设为null，在下次gc的时候就会回收掉了&#125; remove(Object o)需要遍历数组，remove(int index)不需要，只需要判断索引符合范围即可，所以，通常：后者效率更高。 获取元素获取单个元素get(int index)1234567891011/** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position in this list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; rangeCheck(index);//检查索引范围 return (E) elementData[index];//返回元素，并将Object转型为E&#125; 12345678910/** * Checks if the given index is in range. If not, throws an appropriate * runtime exception. This method does *not* check if the index is * negative: It is always used immediately prior to an array access, * which throws an ArrayIndexOutOfBoundsException if index is negative. */private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; 注意rangeCheck检查的是size的大小，也就是实际存储元素个数，而不是容器的实际容量。 #遍历元素 iterator()123public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; Itr是ArryList的一个私有内部类，实现了Iterator接口。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private class Itr implements Iterator&lt;E&gt; &#123; int cursor = 0;//标记位：标记遍历到哪一个元素 int expectedModCount = modCount;//标记位：用于判断是否在遍历的过程中，是否发生了add、remove操作 //检测对象数组是否还有元素 public boolean hasNext() &#123; return cursor != size();//如果cursor==size，说明已经遍历完了，上一次遍历的是最后一个元素 &#125; //获取元素 public E next() &#123; checkForComodification();//检测在遍历的过程中，是否发生了add、remove操作 try &#123; E next = get(cursor++); return next; &#125; catch (IndexOutOfBoundsException e) &#123;//捕获get(cursor++)方法的IndexOutOfBoundsException checkForComodification(); throw new NoSuchElementException(); &#125; &#125; //检测在遍历的过程中，是否发生了add、remove等操作 final void checkForComodification() &#123; if (modCount != expectedModCount)//发生了add、remove操作,这个我们可以查看add等的源代码，发现会出现modCount++ throw new ConcurrentModificationException(); &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125;&#125; 需要注意的是这里有一个Java集合的fail-fast事件。你可能已经注意到，我们在调用add()、remove()这些修改集合的方法时，都会修改一个属性modCount。而我们在遍历集合时，首先会保存一份modCount，然后在遍历时，将保存的modCount和成员变量modCount对比，如果不一样，说明被集合已经被修改，抛出ConcurrentModificationException，产生fail-fast事件。 #其他 设置元素set(int index, E element)123456789/** * 更换特定位置index上的元素为element，返回该位置上的旧值 */ public E set(int index, E element) &#123; RangeCheck(index);//检查索引范围 E oldValue = (E) elementData[index];//旧值 elementData[index] = element;//该位置替换为新值 return oldValue;//返回旧值 &#125; 判断元素是否存在1234567891011121314151617181920212223242526272829303132333435363738/** * 判断动态数组是否包含元素o */public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125;/** * 返回第一个出现的元素o的索引位置 */public int indexOf(Object o) &#123; if (o == null) &#123;//返回第一个null的索引 for (int i = 0; i &lt; size; i++) if (elementData[i] == null) return i; &#125; else &#123;//返回第一个o的索引 for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;//若不包含，返回-1&#125;/** * 返回最后一个出现的元素o的索引位置 */public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size - 1; i &gt;= 0; i--) if (elementData[i] == null) return i; &#125; else &#123; for (int i = size - 1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; #总结1.ArrayList的底层是数组，初始容量是10，当数组满了之后，继续添加元素时，会扩容到原来的1.5倍+1。2.ArrayList保存了一个modCount属性，修改集合的操作都会让其自增。如果在遍历的时候modCount被修改，则会抛出异常，产生fail-fast事件。3.ArrayList内部还维护了一个size属性，它是用来记录数组中的实际元素个数。size,modCount，elementData这些成员变量，都注定了ArrayList线程不安全。4.ArrayList实现了Iterator接口，这表明遍历ArrayList使用普通for循环比使用foreach更快，至于为什么可以参考ArrayList集合实现RandomAccess接口有何作用？为何LinkedList集合却没实现这接口？]]></content>
      <categories>
        <category>java基础</category>
        <category>集合</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 虚拟机内存模型]]></title>
    <url>%2FJVM%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2Findex.html</url>
    <content type="text"><![CDATA[JVM内存模型根据《Java虚拟机规范(Java SE 7 版)》的规定，Java虚拟机所管理的内存包括几下几个运行时数据数据: 程序计数器程序计数器是一块较小的内存空间，它可以看做当前线程所执行的字节码的行号指示器,每个线程都有一个程序计数器。如果线程执行的是Java方法，程序计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的Native方法，这个计数器的值则为空。 Java虚拟机栈线程私有，生命周期和线程相同。每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用到执行完成的过程，都对应着一个栈帧在虚拟机中入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型(指向了一条字节码指令的地址)。 Java虚拟机规范，规定了这个区域的两种异常状况:如果线程请求的栈深度大于虚拟机锁允许的深度，将抛出StackOverflowError；如果虚拟机可以动态扩展(大部分虚拟机都支持),在扩展时无法申请到足够的内存，将抛出OutOfMemoryError异常。 本地方法栈线程私有，作用和虚拟机栈非常相似，只不过虚拟机栈为Java方法服务，本地方法栈为native方法服务。 Java堆Java虚拟机所管理的最大的一块内存，几乎所有的对象实例都在这里分配内存。被所有线程共享。堆内存也是java dc发生的主要区域，因此也被称为GC堆。内内存继续细分的话，可以分为Eden区、From Survivor区、To Survivor区等。堆内存可以是不连续的内存空间，只要逻辑上是连续的即可。可以通过-Xmx和-Xms控制大小。 方法区线程共享，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编辑器编译后的代码等数据。相对而言，GC很少发生在该区域。 方法区有一个运行时常量池(Runtime Constant Pool)，Class文件除了有类的版本、字段、方法接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring@Value注解总是null问题记录]]></title>
    <url>%2Fspring%2FSpring%40Value%E6%B3%A8%E8%A7%A3%E6%80%BB%E6%98%AFnull%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2Findex.html</url>
    <content type="text"><![CDATA[问题描述在使用@value注解之后，字段总是为空。后来发现是因为字段使用了static修饰。123456789@Componentpublic class TestValue &#123; @Value(&quot;$&#123;appEnv&#125;&quot;) private static String appenv; //null public String test() &#123; return appenv; &#125;&#125; 原因spring的依赖注入不支持为static变量注入。spring 依赖注入的底层原理还是利用反射来创建对象。而static变量，在jvm加载类的时候便已经创建，存在于方法区，被所有实例共享，属于类的属性而不是对象的属性。spring是基于对象层面的依赖注入。 解决1.使用set方法注入，非静态setter 方法注入静态变量。如：1234567891011121314import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component public class GlobalValue &#123; public static String DATABASE; @Value(&quot;$&#123;mongodb.db&#125;&quot;) public void setDatabase(String db) &#123; DATABASE = db; &#125; &#125; 2.@PostConstruct方式实现1234567891011121314151617import org.mongodb.morphia.AdvancedDatastore; import org.springframework.beans.factory.annotation.Autowired; @Component public class MongoFileOperationUtil &#123; @Autowired private static AdvancedDatastore dsForRW; private static MongoFileOperationUtil mongoFileOperationUtil; @PostConstruct public void init() &#123; mongoFileOperationUtil = this; mongoFileOperationUtil.dsForRW = this.dsForRW; &#125; &#125; @PostConstruct，会在构造方法之后执行。其给static变量赋值的原理和set方法差不多，都是调用非静态方法给静态变量赋值]]></content>
      <categories>
        <category>spring</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[netty系列之--1.netty框架基本介绍]]></title>
    <url>%2Fnetty%2Fnetty1%2Findex.html</url>
    <content type="text"><![CDATA[netty是什么？]]></content>
      <categories>
        <category>netty</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性 使用Optional避免NPE]]></title>
    <url>%2Fjava8%2Foptional%2Findex.html</url>
    <content type="text"><![CDATA[前言相信每一个Java程序员都碰到过NPE异常，每个避免NPE，往往会在代码中写很多if判断，形成代码污染。为了解决这个问题，Google公司著名的Guava项目引入了Optional类，Guava通过使用检查空值的方式来防止代码污染，它鼓励程序员写更干净的代码。受到Google Guava的启发，Optional类已经成为Java 8类库的一部分。 Optional类介绍Optional类存在于java.util包中，它是一个用来存放null值或者非null值的容器。如果容器内有值，isPresent()方法返回true,使用get()方法可以取到这个值.除此之外，还提供了基于对值存在与否的判断的其他方法，比如：orElse()(如果值不存在，则返回默认值)ifPresent()(如果值存在，则执行代码块)需要注意的是，这是一个“基于值(value-based)”的类，使用对身份敏感的操作，比如(比较符号’==’,一致性哈希或同步)都可能出现意想不到的结果，这类操作应该避免。什么是value-based class? Optional类的方法注:第一排:m:表示方法,左下角有个白色标志的表示static方法 f:表示变量第二排:上锁表示为private方法,解锁表示public第三排:方法或变量名称第四排:方法返回值 我们一个个看 empty() 创建一个空的Optional对象public static Optional empty()返回一个Optional对象，其存储的值是null1234Optional&lt;Object&gt; emptyOptional = Optional.empty();System.out.println(emptyOptional);result:Optional.empty 注意判断Optional值是否为Null,不要使用null == Optional.empty(),而应该使用isPresent() of() 创建一个不为空的Optional对象，如果值为null，抛出NPE1234Optional&lt;Object&gt; optional = Optional.of(1);System.out.println(optional);result:Optional[1] ofNullable()创建一个可为空的Optional对象12345678Optional&lt;Object&gt; emptyOptional = Optional.ofNullable(null);Optional&lt;Long&gt; longOptional = Optional.ofNullable(2L);System.out.println(emptyOptional);System.out.println(longOptional);result: Optional.empty Optional[2] isPresent() 判断值是否存在public boolean isPresent()12345678910Optional&lt;Object&gt; optional = Optional.of(1);Optional&lt;Object&gt; emptyOptional = Optional.ofNullable(null);boolean isPresent = optional.isPresent();boolean emptyOptionalPresent = emptyOptional.isPresent();System.out.println(isPresent);System.out.println(emptyOptionalPresent);result: true false ifPresent() 注意不是isPresent()当值存在的时候，执行传入的代码1234Optional&lt;Object&gt; optional = Optional.of(1);optional.ifPresent(e-&gt; System.out.println((Integer)e+1));result:2 orElse() 如果存在返回原来的值，不存在，则返回指定的值public T orElse(T other) 12345678910Optional&lt;Object&gt; optional = Optional.of(1);Optional&lt;Object&gt; emptyOptional = Optional.empty();Object orElse = optional.orElse(2);Object orElse2 = emptyOptional.orElse(2);System.out.println(orElse);System.out.println(orElse2);result: 1 2 稍微复杂点的例子:1234567891011121314151617181920212223242526public class User &#123; private String name; private Integer age; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public Integer getAge() &#123; return age; &#125;&#125;List&lt;User&gt; userList = Arrays.asList(new User(&quot;李四&quot;, 20), new User(&quot;张三&quot;, 18), new User(&quot;王五&quot;, 25));User user = userList.stream().filter(e -&gt; e.getAge() &gt; 25).findFirst().orElse(new User(&quot;王老五&quot;, 30));System.out.println(user.getName());result:王老五 orElseGet() 如果存在，返回原来的值，如果不存在，返回返回函数式接口的结果public T orElseGet(Supplier&lt;? extends T&gt; other)和orElse不同的是，这个可以传入一个函数表达式123456Optional&lt;Object&gt; emptyOptional = Optional.empty();String name = &quot;王老五&quot;;Object orElseGet = emptyOptional.orElseGet(name::length);System.out.println(orElseGet);result:3 orElseThrow 如果存在，返回原来的值，如果不存在，抛出一个指定的异常public T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X 123456Optional&lt;Object&gt; emptyOptional = Optional.empty();Object orElseThrow = emptyOptional.orElseThrow(()-&gt;new RuntimeException(&quot;程序异常&quot;));result:Exception in thread &quot;main&quot; java.lang.RuntimeException: 程序异常... filter() 按要求返回过滤后的元素，没有返回一个空的Optional对象public Optional filter(Predicate&lt;? super T&gt; predicate)1234567891011Optional&lt;Object&gt; optional = Optional.of(1);Optional&lt;Object&gt; emptyOptional = Optional.empty();Optional&lt;Object&gt; optionalO = optional.filter(e -&gt; e.equals(1));Optional&lt;Object&gt; optionalO1 = emptyOptional.filter(e -&gt; e.equals(1));System.out.println(optionalO);System.out.println(optionalO1);result: Optional[1] Optional.empty map() 对Optional中保存的值进行函数运算，并返回新的Optional,里面保存的值可以是任何类型12345User user = new User(&quot;李四&quot;, 20);Optional&lt;Integer&gt; optionalInteger = Optional.of(new User(&quot;李四&quot;, 20)).map(User::getAge);System.out.println(optionalInteger);result:Optional[20] flatMap() 和map(),区别在于，保存的只只能和调用方一样123456789101112User user = new User(&quot;李四&quot;, 20);Optional&lt;User&gt; user1 = userOptional.flatMap(e -&gt; &#123; if (e.getAge() &gt; 19) &#123; return Optional.of(new User(&quot;张三&quot;, 21)); &#125; else &#123; return Optional.of(new User(&quot;王五&quot;, 18)); &#125;&#125;);System.out.println(user1.get().getName());result:张三]]></content>
      <categories>
        <category>java8</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo+travis+阿里云oss持续集成个人博客]]></title>
    <url>%2Fother%2Fhexo%20travis%20%E9%98%BF%E9%87%8C%E4%BA%91oss%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2Findex.html</url>
    <content type="text"><![CDATA[这两天抽空用hexo搭建了一个静态博客，并且使用travis+github pages做持续集成。后来对github pages的响应速度不是很满意，便将博客换成了hexo+travis+oss。 实现的效果是只需要提交代码，便自动将博客更新到github pages 和oss上面。 使用hexo+travis+github pages 完成持续部署的过程不在赘述，网上有很多教程，不过质量参差不齐，这里推荐一篇：使用Travis CI自动部署Hexo博客 按照这篇文章操作，应该就可以实现hexo+travis+github pages持续集成。我在这个基础上，增加了对oss的持续集成。 有关oss如何部署静态页面，参考如何将 hexo 生成的博客部署至阿里云 OSS 并全站启用 CDN 加速访问 值得一提的是，如果需要将oss绑定到域名，需要备案。 接下来需要做的是在push代码的时候，将构建出来的静态文件上传到oss中。这里我使用的是阿里云oss提供的工具类：命令行工具ossutil 首先将ossutil下载，放到hexo源码根目录: 在上传只github pages的基础上，增加以下代码:1234567891011# 进入根目录cd ../# 开启权限chmod 755 ossutil64# 配置endpoint，id 秘钥./ossutil64 config -e &lt;your oss endpoint&gt; -i &lt;your AccessKey ID&gt; -k &lt;your Access Key Secret&gt;# 先删除所有文件，防止出现文件改名后不能覆盖的问题./ossutil64 rm oss://keji-blog-hexo -r -f# 上传public文件至oss./ossutil64 cp public oss://keji-blog-hexo/ -r -f --loglevel=debug 这样，便可以了。]]></content>
      <categories>
        <category>other</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[BigDecimal使用案例]]></title>
    <url>%2Fjava%E5%9F%BA%E7%A1%80%2FBigDecimal%2FBigDecimal%2Findex.html</url>
    <content type="text"><![CDATA[创建BigDecimal对象创建BigDecimal对象常用的方式有2种：12BigDecimal a = new Bigdecimal(1);BigDecimal a1 = BigDecimal.valueOf(1); 不推荐使用new 关键字创建Bigdecimal对象。原因是当new 的值是一个小数的时候，其真实的值并不是我们想要的值1234BigDecimal b = new BigDecimal(1.1);BigDecimal b1 = BigDecimal.valueOf(1.1);System.out.println("new的值b: "+b);System.out.println("valueOf()的值b1: "+b1); 输出:121.100000000000000088817841970012523233890533447265625valueOf()的值b1: 1.1 这在比较大小的时候，很可能出现意想不到的结果。 例如: 123BigDecimal a = new BigDecimal(1.1);String b = "1.1";System.out.println(a.toString().equals(b)); //fasle 如果不注意，很可能产生bug。 加法加法的方法有两种，方法签名如下:12public BigDecimal add(BigDecimal augend)public BigDecimal add(BigDecimal augend, MathContext mc) MathContext 用于指定精度和舍入模式，具体查看官方javadoc demo:12345678910111213BigDecimal a = BigDecimal.valueOf(1);BigDecimal b = BigDecimal.valueOf(1.5);BigDecimal c = BigDecimal.valueOf(1.4);BigDecimal addResult = a.add(b);BigDecimal addResult1 = a.add(b,new MathContext(2));BigDecimal addResult2 = a.add(b,new MathContext(1));BigDecimal addResult3 = a.add(c,new MathContext(1));System.out.println("addResult: "+addResult);System.out.println("addResult1: "+addResult1);System.out.println("addResult2: "+addResult2);System.out.println("addResult3: "+addResult3); result:1234addResult: 2.5addResult1: 2.5addResult2: 3addResult3: 2 mc 设置保留几位小数，舍入按四舍五入 减法方法签名如下：12public BigDecimal subtract(BigDecimal subtrahend)public BigDecimal subtract(BigDecimal subtrahend, MathContext mc) demo：12345678910111213BigDecimal a = BigDecimal.valueOf(1);BigDecimal b = BigDecimal.valueOf(1.5);BigDecimal c = BigDecimal.valueOf(1.4);BigDecimal subtract = a.subtract(b);BigDecimal subtract1 = a.subtract(b,new MathContext(2));BigDecimal subtract2 = a.subtract(b,new MathContext(1));BigDecimal subtract3 = a.subtract(c,new MathContext(1));System.out.println("subtract: "+subtract);System.out.println("subtract1: "+subtract1);System.out.println("subtract2: "+subtract2);System.out.println("subtract3: "+subtract3); result：1234subtract: -0.5subtract1: -0.5subtract2: -0.5subtract3: -0.4 乘法：方法签名:12public BigDecimal multiply(BigDecimal multiplicand)public BigDecimal multiply(BigDecimal multiplicand, MathContext mc) demo:12345678910111213BigDecimal a = BigDecimal.valueOf(1);BigDecimal b = BigDecimal.valueOf(1.5);BigDecimal c = BigDecimal.valueOf(1.4);BigDecimal multiply = a.multiply(b);BigDecimal multiply1 = a.multiply(b,new MathContext(2));BigDecimal multiply2 = a.multiply(b,new MathContext(1));BigDecimal multiply3 = a.multiply(c,new MathContext(1));System.out.println("multiply: "+multiply);System.out.println("multiply1: "+multiply1);System.out.println("multiply2: "+multiply2);System.out.println("multiply3: "+multiply3); result:1234multiply: 1.5multiply1: 1.5multiply2: 2multiply3: 1 除法:123456public BigDecimal divide(BigDecimal divisor)public BigDecimal divide(BigDecimal divisor, MathContext mc)public BigDecimal divide(BigDecimal divisor, int roundingMode)public BigDecimal divide(BigDecimal divisor, RoundingMode roundingMode)public BigDecimal divide(BigDecimal divisor, int scale, RoundingMode roundingMode)public BigDecimal divide(BigDecimal divisor, int scale, int roundingMode) 其中 public BigDecimal divide(BigDecimal divisor) 不推荐使用。idea警告如下:123456Inspection info: Reports calls to divide() or setScale() without a rounding mode argument. Such calls can lead to an ArithmeticException when the exact value cannot be represented in the result (e.g. because it has a non-terminating decimal expansion). Specifying a rounding mode prevents the ArithmeticException.翻译:检查信息:报告调用divide()或setScale()，而不带舍入模式参数。当结果中不能表示精确值时，这种调用可能导致算术异常(例如，因为它具有无限的十进制展开)。指定舍入模式可以防止算术异常。简单点说就是除不尽的时候会报错 所以用除法的时候，我们需要指定其舍入模式。推荐使用:12public BigDecimal divide(BigDecimal divisor, int scale, RoundingMode roundingMode)public BigDecimal divide(BigDecimal divisor, int scale, int roundingMode) 指定舍入模式，和保留几位小数 demo:12BigDecimal divide = a.divide(b, 2, BigDecimal.ROUND_HALF_UP);System.out.println("divide: "+divide);]]></content>
      <categories>
        <category>java基础</category>
        <category>BigDecimal</category>
      </categories>
  </entry>
</search>
